# -*- coding: utf-8 -*-
"""
FlagSniff Pro - Modern Web Interface
A next-generation PCAP analysis tool with AI capabilities
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import networkx as nx
from datetime import datetime
import json
import tempfile
import os
import re

# Import enhanced analyzer and AI agent
try:
    from web_analyzer import WebPcapAnalyzer, analyze_sample_pcap
    from ai_agent import create_agent, AgentConfig
    from flagsniff_ai import setup_ai_agent, analyze_with_ai
    
    # Import CTF modules
    from ctf_steganography import SteganographyDetector
    from ctf_encoding_chains import EncodingChainAnalyzer
    from ctf_exploit_workshop import ExploitWorkshop
    from ctf_ui_enhancements import CTFUIEnhancements
    from ctf_visual_analysis import VisualAnalysisTools
    from ctf_automated_reporting import AutomatedReporting
    
    IMPORTS_OK = True
except ImportError as e:
    st.error(f"Import error: {e}")
    IMPORTS_OK = False

# Add rate limit handling
import time
import random
from typing import Optional, Dict, Any

class RateLimitHandler:
    """Handles API rate limiting with exponential backoff and fallback models"""
    
    def __init__(self):
        self.rate_limit_errors = {}
        self.fallback_models = [
            "qwen/qwen3-235b-a22b:free",
            "openai/gpt-oss-20b:free",
            "cognitivecomputations/dolphin-mistral-24b-venice-edition:free",
            "qwen/qwen2.5-vl-32b-instruct:free"
        ]
        self.current_model_index = 0
    
    def handle_rate_limit(self, model: str, error_msg: str) -> Optional[str]:
        """Handle rate limit error and suggest fallback model"""
        self.rate_limit_errors[model] = {
            'timestamp': time.time(),
            'error': error_msg
        }
        
        # Try next fallback model
        if self.current_model_index < len(self.fallback_models) - 1:
            self.current_model_index += 1
            return self.fallback_models[self.current_model_index]
        
        return None
    
    def get_available_models(self) -> list:
        """Get list of models that haven't hit rate limits recently"""
        current_time = time.time()
        available = []
        
        for model in self.fallback_models:
            if model not in self.rate_limit_errors:
                available.append(model)
            elif current_time - self.rate_limit_errors[model]['timestamp'] > 300:  # 5 minutes
                available.append(model)
        
        return available
    
    def reset_errors(self):
        """Reset rate limit errors"""
        self.rate_limit_errors.clear()
        self.current_model_index = 0

# Initialize rate limit handler
if 'rate_limit_handler' not in st.session_state:
    st.session_state.rate_limit_handler = RateLimitHandler()

# Page config
st.set_page_config(
    page_title="FlagSniff Pro",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# Initialize session state
if 'theme' not in st.session_state:
    st.session_state.theme = 'dark'
if 'current_page' not in st.session_state:
    st.session_state.current_page = 'analyzer'
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None

# Initialize advanced CTF features session state variables
if 'steganography_detector' not in st.session_state:
    if IMPORTS_OK:
        try:
            st.session_state.steganography_detector = SteganographyDetector()
        except Exception as e:
            st.session_state.steganography_detector = None
    else:
        st.session_state.steganography_detector = None
        
if 'encoding_analyzer' not in st.session_state:
    if IMPORTS_OK:
        try:
            st.session_state.encoding_analyzer = EncodingChainAnalyzer()
        except Exception as e:
            st.session_state.encoding_analyzer = None
    else:
        st.session_state.encoding_analyzer = None
        
if 'exploit_workshop' not in st.session_state:
    if IMPORTS_OK:
        try:
            st.session_state.exploit_workshop = ExploitWorkshop()
        except Exception as e:
            st.session_state.exploit_workshop = None
    else:
        st.session_state.exploit_workshop = None
        
if 'ui_enhancements' not in st.session_state:
    if IMPORTS_OK:
        try:
            st.session_state.ui_enhancements = CTFUIEnhancements()
        except Exception as e:
            st.session_state.ui_enhancements = None
    else:
        st.session_state.ui_enhancements = None
        
if 'visual_analysis' not in st.session_state:
    if IMPORTS_OK:
        try:
            st.session_state.visual_analysis = VisualAnalysisTools()
        except Exception as e:
            st.session_state.visual_analysis = None
    else:
        st.session_state.visual_analysis = None
        
if 'automated_reporting' not in st.session_state:
    if IMPORTS_OK:
        try:
            st.session_state.automated_reporting = AutomatedReporting()
        except Exception as e:
            st.session_state.automated_reporting = None
    else:
        st.session_state.automated_reporting = None
        
if 'ctf_visualizer' not in st.session_state:
    st.session_state.ctf_visualizer = None

def get_theme_styles():
    """Get CSS styles based on current theme"""
    if st.session_state.theme == 'dark':
        return """
        <style>
        .stApp {
            background: linear-gradient(135deg, #0c0c0c 0%, #1a1a2e 50%, #16213e 100%);
            color: white;
        }
        
        #MainMenu {visibility: hidden;}
        footer {visibility: hidden;}
        header {visibility: hidden;}
        
        .nav-container {
            background: rgba(255, 255, 255, 0.05);
            backdrop-filter: blur(20px);
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 20px;
            padding: 1rem 2rem;
            margin: 1rem 0 2rem 0;
            text-align: center;
        }
        
        .nav-brand {
            font-size: 1.8rem;
            font-weight: 700;
            background: linear-gradient(45deg, #00f5ff, #ff00ff, #ffff00);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        
        .glass-card {
            background: rgba(255, 255, 255, 0.05);
            backdrop-filter: blur(20px);
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 20px;
            padding: 2rem;
            margin: 1rem 0;
        }
        
        .feature-card {
            background: linear-gradient(135deg, rgba(0, 245, 255, 0.1) 0%, rgba(255, 0, 255, 0.1) 100%);
            border: 1px solid rgba(255, 255, 255, 0.2);
            border-radius: 20px;
            padding: 2rem;
            text-align: center;
            margin: 1rem 0;
        }
        </style>
        """
    else:
        return """
        <style>
        .stApp {
            background: linear-gradient(135deg, #f0f9ff 0%, #e0f2fe 50%, #bae6fd 100%);
            color: #1e293b;
        }
        
        #MainMenu {visibility: hidden;}
        footer {visibility: hidden;}
        header {visibility: hidden;}
        
        .nav-container {
            background: rgba(255, 255, 255, 0.9);
            backdrop-filter: blur(20px);
            border: 1px solid rgba(0, 0, 0, 0.1);
            border-radius: 20px;
            padding: 1rem 2rem;
            margin: 1rem 0 2rem 0;
            text-align: center;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
        }
        
        .nav-brand {
            font-size: 1.8rem;
            font-weight: 700;
            background: linear-gradient(45deg, #3b82f6, #8b5cf6, #ec4899);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        
        .glass-card {
            background: rgba(255, 255, 255, 0.85);
            backdrop-filter: blur(20px);
            border: 1px solid rgba(59, 130, 246, 0.2);
            border-radius: 20px;
            padding: 2rem;
            margin: 1rem 0;
            box-shadow: 0 8px 32px rgba(59, 130, 246, 0.15);
        }
        
        .feature-card {
            background: linear-gradient(135deg, rgba(59, 130, 246, 0.15) 0%, rgba(139, 92, 246, 0.15) 100%);
            border: 1px solid rgba(0, 0, 0, 0.2);
            border-radius: 20px;
            padding: 2rem;
            text-align: center;
        }
        </style>
        """

def render_navigation():
    """Render navigation bar"""
    theme_icon = "üåô" if st.session_state.theme == 'light' else "‚òÄÔ∏è"
    
    st.markdown("""
    <div class="nav-container">
        <div class="nav-brand">üîç FlagSniff Pro</div>
    </div>
    """, unsafe_allow_html=True)
    
    nav_cols = st.columns([1, 1, 1, 1, 1])
    
    with nav_cols[0]:
        if st.button("üîç Analyzer", key="nav_analyzer", use_container_width=True, 
                    type="primary" if st.session_state.current_page == 'analyzer' else "secondary"):
            st.session_state.current_page = 'analyzer'
            st.rerun()
    
    with nav_cols[1]:
        if st.button("ü§ñ AI Config", key="nav_ai_config", use_container_width=True,
                    type="primary" if st.session_state.current_page == 'ai_config' else "secondary"):
            st.session_state.current_page = 'ai_config'
            st.rerun()
    
    with nav_cols[2]:
        if st.button("üìä Results", key="nav_results", use_container_width=True,
                    type="primary" if st.session_state.current_page == 'results' else "secondary"):
            st.session_state.current_page = 'results'
            st.rerun()
    
    with nav_cols[3]:
        if st.button("‚ÑπÔ∏è About", key="nav_about", use_container_width=True,
                    type="primary" if st.session_state.current_page == 'about' else "secondary"):
            st.session_state.current_page = 'about'
            st.rerun()
    
    with nav_cols[4]:
        if st.button(f"{theme_icon} Theme", key="theme_toggle", use_container_width=True):
            st.session_state.theme = 'light' if st.session_state.theme == 'dark' else 'dark'
            st.rerun()
    
    st.markdown("<br>", unsafe_allow_html=True)

def render_hero():
    """Render hero section"""
    st.markdown("""
    <div style="text-align: center; padding: 4rem 2rem; background: linear-gradient(135deg, rgba(0, 245, 255, 0.1) 0%, rgba(255, 0, 255, 0.1) 100%); border-radius: 30px; margin: 2rem 0;">
        <h1 style="font-size: 3.5rem; font-weight: 700; background: linear-gradient(45deg, #00f5ff, #ff00ff); -webkit-background-clip: text; -webkit-text-fill-color: transparent; margin-bottom: 1rem;">Next-Gen PCAP Analysis</h1>
        <p style="font-size: 1.3rem; margin-bottom: 0;">Powered by Advanced AI ‚Ä¢ Built for Security Professionals ‚Ä¢ Optimized for CTF</p>
    </div>
    """, unsafe_allow_html=True)

def render_analyzer_page():
    """Render main analyzer page"""
    
    # Check if analysis is running and show live indicator
    if st.session_state.get('analysis_running', False):
        st.info("üîÑ **Analysis in Progress** - Progress will update in real-time below. Please wait for completion...")
        
        # Show live progress data if available
        if 'progress_data' in st.session_state:
            progress_data = st.session_state.progress_data
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("üïí Phase", progress_data.get('phase', 'Unknown'))
            with col2:
                st.metric("üìà Progress", f"{progress_data.get('progress', 0):.1f}%")
            with col3:
                st.metric("‚è±Ô∏è Elapsed", f"{progress_data.get('elapsed', 0):.1f}s")
            with col4:
                st.metric("üïí Remaining", f"{progress_data.get('remaining', 0):.1f}s")
    
    # Rate limit status banner
    rate_handler = st.session_state.rate_limit_handler
    if rate_handler.rate_limit_errors:
        st.warning("‚ö†Ô∏è **AI Service Notice**: Some AI models are experiencing rate limits. Offline analysis features remain fully functional and will provide comprehensive results.")
        
        # Show quick status
        with st.expander("üìä AI Service Status", expanded=False):
            available_count = len(rate_handler.get_available_models())
            total_count = len(rate_handler.fallback_models)
            st.info(f"üü¢ Available: {available_count}/{total_count} models")
            st.info("üí° Visit AI Config page to switch models or wait for rate limits to reset")
    
    # Feature cards
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown("""
        <div class="feature-card">
            <div style="font-size: 3rem; margin-bottom: 1rem;">üö©</div>
            <div style="font-size: 1.3rem; font-weight: 600; margin-bottom: 0.5rem;">Flag Hunter</div>
            <div style="font-size: 0.9rem;">Advanced pattern recognition for CTF flags</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="feature-card">
            <div style="font-size: 3rem; margin-bottom: 1rem;">üîê</div>
            <div style="font-size: 1.3rem; font-weight: 600; margin-bottom: 0.5rem;">Credential Extractor</div>
            <div style="font-size: 0.9rem;">Detect passwords, tokens, and API keys</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class="feature-card">
            <div style="font-size: 3rem; margin-bottom: 1rem;">ü§ñ</div>
            <div style="font-size: 1.3rem; font-weight: 600; margin-bottom: 0.5rem;">AI Analysis</div>
            <div style="font-size: 0.9rem;">Machine learning powered insights</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        st.markdown("""
        <div class="feature-card">
            <div style="font-size: 3rem; margin-bottom: 1rem;">‚ö°</div>
            <div style="font-size: 1.3rem; font-weight: 600; margin-bottom: 0.5rem;">Real-time</div>
            <div style="font-size: 0.9rem;">Lightning fast processing</div>
        </div>
        """, unsafe_allow_html=True)
    
    # Main analyzer interface
    st.markdown('<div class="glass-card">', unsafe_allow_html=True)
    
    st.markdown("### üìÅ Upload PCAP File")
    uploaded_file = st.file_uploader(
        "Choose your PCAP file",
        type=['pcap', 'pcapng'],
        help="Upload .pcap or .pcapng files for analysis"
    )
    
    if uploaded_file:
        st.success(f"‚úÖ File loaded: {uploaded_file.name} ({uploaded_file.size:,} bytes)")
        
        # Analysis options
        st.markdown("### ‚öôÔ∏è Analysis Configuration")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**üéØ Search Targets**")
            search_flags = st.checkbox("üö© CTF Flags", value=True)
            search_creds = st.checkbox("üîê Credentials", value=True)
            search_tokens = st.checkbox("üé´ API Tokens", value=True)
            search_emails = st.checkbox("üìß Email Addresses", value=False)
            search_hashes = st.checkbox("üîí Hash Values", value=False)
            
            st.markdown("**üèÜ Analysis Mode**")
            ctf_mode = st.checkbox("üéØ CTF Challenge Mode", value=True, help="Enable advanced CTF-specific analysis techniques")
        
        with col2:
            st.markdown("**ü§ñ AI Configuration**")
            
            if IMPORTS_OK:
                try:
                    current_api_key = AgentConfig.get_api_key()
                    ai_enabled = current_api_key is not None
                    
                    if ai_enabled:
                        current_config = AgentConfig.load_config()
                        current_model = current_config.get('model', 'qwen/qwen3-235b-a22b:free')
                        
                        # Check rate limit status
                        rate_handler = st.session_state.rate_limit_handler
                        if current_model in rate_handler.rate_limit_errors:
                            st.error(f"üî¥ AI Agent Rate Limited - Model: {current_model.split('/')[-1]}")
                            st.info("üí° Switch to another model in AI Config or use offline analysis")
                            st.info("üîÑ Offline analysis will still provide comprehensive results with pattern matching and protocol analysis")
                            ai_enabled = False
                        else:
                            st.success(f"üü¢ AI Agent Online - Model: {current_model.split('/')[-1]}")
                        
                        if ai_enabled:
                            ai_mode = st.selectbox(
                                "Analysis Mode",
                                [
                                    "üß† Enhanced Analysis (Multi-Model Ensemble)", 
                                    "üéØ Deep Flag Hunt (Specialized Agent)", 
                                    "üî¨ Protocol Analysis (Security Expert)", 
                                    "üîê Credential Hunt (Auth Specialist)",
                                    "üß† Behavioral Analysis (Anomaly Detection)",
                                    "üìä Standard Only"
                                ],
                                help="Choose your AI analysis strategy"
                            )
                            
                            confidence_threshold = st.slider("Confidence Threshold", 0, 100, 70)
                        else:
                            ai_mode = "üìä Standard Only"
                            confidence_threshold = 70
                    
                    else:
                        st.warning("üî¥ AI Agent Offline - Configure API key to enable AI features")
                        
                        # Show what's still available
                        st.info("üìä **Available Features**: Standard analysis with comprehensive pattern matching, protocol analysis, and statistical insights")
                        
                        ai_mode = "üìä Standard Only"
                        confidence_threshold = 70
                except Exception as e:
                    st.error(f"AI configuration error: {e}")
                    ai_enabled = False
                    ai_mode = "üìä Standard Only"
                    confidence_threshold = 70
            else:
                st.warning("üî¥ AI features unavailable - Import error")
                ai_enabled = False
                ai_mode = "üìä Standard Only"
                confidence_threshold = 70
        
        # Custom regex
        st.markdown("### üéØ Custom Pattern")
        custom_regex = st.text_input(
            "Custom Regex Pattern",
            placeholder="flag\\{.*?\\}",
            help="Enter your custom regex pattern for specialized searches"
        )

        # User-supplied decryption key/password
        st.markdown("### üõ°Ô∏è Decryption Key/Password (Optional)")
        user_decrypt_key = st.text_input(
            "Decryption Key or Password",
            placeholder="Enter key/password for encrypted data (optional)",
            help="If you suspect encrypted data, provide a key or password to attempt decryption."
        )
        
        # CTF Challenge Context
        st.markdown("### üèÜ CTF Challenge Context")
        col1, col2 = st.columns(2)
        
        with col1:
            challenge_description = st.text_area(
                "Challenge Description",
                placeholder="e.g., 'Find the hidden flag in network traffic. The admin mentioned something about DNS...'",
                help="Describe the CTF challenge, any hints, or context clues",
                height=100
            )
        
        with col2:
            challenge_hints = st.text_area(
                "Additional Hints/Clues",
                placeholder="e.g., 'Look for base64 encoding', 'Check HTTP headers', 'Steganography involved'",
                help="Any additional hints, clues, or specific techniques mentioned",
                height=100
            )
        
        challenge_category = st.selectbox(
            "Challenge Category (Optional)",
            [
                "üîç General Analysis",
                "üåê Web Exploitation", 
                "üîê Cryptography",
                "üïµÔ∏è Steganography",
                "üåç Network Analysis",
                "üîì Reverse Engineering",
                "üì° Forensics",
                "üé≠ Social Engineering"
            ],
            help="Select the challenge category to help AI focus its analysis"
        )
        
        # Analysis button
        st.markdown("---")
        
        # Analysis mode indicator
        if not ai_enabled and rate_handler.rate_limit_errors:
            st.info("üîÑ **Analysis Mode**: Offline Analysis (AI services temporarily unavailable)")
        elif ai_enabled:
            st.success("ü§ñ **Analysis Mode**: AI-Enhanced Analysis")
        else:
            st.info("üìä **Analysis Mode**: Standard Analysis")
        
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            analysis_running = st.session_state.get('analysis_running', False)
            button_text = "üîÑ ANALYSIS RUNNING..." if analysis_running else "üöÄ START ANALYSIS"
            button_disabled = analysis_running
            
            if st.button(button_text, key="analyze_btn", use_container_width=True, disabled=button_disabled):
                if IMPORTS_OK:
                    ctf_context = {
                        'description': challenge_description,
                        'hints': challenge_hints,
                        'category': challenge_category
                    }
                    
                    run_analysis(uploaded_file, {
                        'flags': search_flags,
                        'credentials': search_creds,
                        'tokens': search_tokens,
                        'emails': search_emails,
                        'hashes': search_hashes,
                        'ctf_mode': ctf_mode
                    }, custom_regex, ai_mode, ai_enabled, confidence_threshold, ctf_context, user_decrypt_key)
                else:
                    st.error("Cannot run analysis - Import error detected")
    
    else:
        # Upload area
        st.markdown("""
        <div style="border: 2px dashed rgba(0, 245, 255, 0.5); border-radius: 20px; padding: 3rem; text-align: center; background: rgba(0, 245, 255, 0.05);">
            <div style="font-size: 3rem; margin-bottom: 1rem;">üìÅ</div>
            <div style="font-size: 1.2rem; font-weight: 600; margin-bottom: 0.5rem;">Drop your PCAP file here</div>
            <div style="color: rgba(255, 255, 255, 0.7);">Supports .pcap and .pcapng formats</div>
        </div>
        """, unsafe_allow_html=True)
        
        # Offline analysis info
        if rate_handler.rate_limit_errors:
            st.info("üí° **Offline Analysis Available**: Even when AI services are rate limited, you can still analyze PCAP files with advanced pattern matching, protocol analysis, and CTF-specific detection algorithms.")
        
        # Demo buttons
        st.markdown("### üéÆ Try Demo")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üß™ Standard Demo", use_container_width=True):
                if IMPORTS_OK:
                    run_demo_analysis(False)
                else:
                    st.error("Demo unavailable - Import error")
        
        with col2:
            # Add progress test button
            if st.button("üîÑ Test Progress", use_container_width=True):
                test_progress_tracker()
        
        with col3:
            if st.button("üîç Deep Hunt Demo", use_container_width=True, disabled=not IMPORTS_OK or not AgentConfig.get_api_key()):
                if IMPORTS_OK:
                    run_demo_analysis(True, "deep_hunt")
                else:
                    st.error("Demo unavailable - Import error")
    
    st.markdown('</div>', unsafe_allow_html=True)

def render_ai_config_page():
    """Render AI configuration page"""
    st.markdown('<div class="glass-card">', unsafe_allow_html=True)
    
    st.markdown("### ü§ñ AI Agent Configuration")
    
    if not IMPORTS_OK:
        st.error("AI configuration unavailable - Import error detected")
        st.markdown('</div>', unsafe_allow_html=True)
        return
    
    # Rate limit status and handling
    rate_handler = st.session_state.rate_limit_handler
    available_models = rate_handler.get_available_models()
    
    if rate_handler.rate_limit_errors:
        st.warning("‚ö†Ô∏è Some AI models are experiencing rate limits. Available models are highlighted below.")
        
        # Show rate limit errors
        with st.expander("üö´ Rate Limit Status", expanded=False):
            for model, error_info in rate_handler.rate_limit_errors.items():
                time_since_error = int(time.time() - error_info['timestamp'])
                if time_since_error < 300:  # 5 minutes
                    st.error(f"‚ùå {model}: Rate limited ({300 - time_since_error}s until retry)")
                else:
                    st.info(f"‚úÖ {model}: Available for retry")
        
        # Reset button
        if st.button("üîÑ Reset Rate Limit Status"):
            rate_handler.reset_errors()
            st.rerun()
    
    # Free models highlight with availability status
    if available_models:
        st.success(f"üÜì FREE AI Models Available! {len(available_models)} models ready to use.")
    else:
        st.warning("‚ö†Ô∏è All free models are currently rate limited. Please wait a few minutes or use offline analysis.")
    
    # Current status
    try:
        current_config = AgentConfig.load_config()
        current_api_key = AgentConfig.get_api_key()
        current_model = current_config.get('model', 'qwen/qwen3-235b-a22b:free')
        
        if current_api_key:
            # Check if current model is rate limited
            if current_model in rate_handler.rate_limit_errors:
                st.error(f"üî¥ Current Model Rate Limited: {current_model}")
                st.info("üí° Switch to an available model below or wait for rate limit to reset.")
            else:
                st.success(f"üü¢ AI Agent Configured - Model: {current_model}")
            
            # Model change section
            st.markdown("### üîÑ Change AI Model")
            
            model_options = {
                # NEW VERIFIED WORKING FREE MODELS
                "qwen/qwen3-235b-a22b:free": "üÜì Qwen3 235B A22B: Advanced reasoning - FREE",
                "openai/gpt-oss-20b:free": "üÜì OpenAI GPT-OSS-20B: OpenAI architecture - FREE", 
                "cognitivecomputations/dolphin-mistral-24b-venice-edition:free": "üÜì Dolphin Mistral Venice 24B: Enhanced reasoning - FREE",
                "qwen/qwen2.5-vl-32b-instruct:free": "üÜì Qwen2.5 VL 32B: Vision-language model - FREE"
            }
            
            # Filter models by availability
            available_model_keys = [key for key in model_options.keys() if key not in rate_handler.rate_limit_errors]
            
            if available_model_keys:
                selected_model = st.selectbox(
                    "Select AI Model",
                    available_model_keys,
                    format_func=lambda x: f"{model_options[x]} {'‚úÖ' if x not in rate_handler.rate_limit_errors else '‚ùå'}",
                    index=available_model_keys.index(current_model) if current_model in available_model_keys else 0
                )
                
                # Show model status
                if selected_model in rate_handler.rate_limit_errors:
                    st.error(f"‚ö†Ô∏è This model is currently rate limited. Consider choosing another model.")
                
                if st.button("üîÑ CHANGE MODEL", use_container_width=True, disabled=selected_model == current_model):
                    current_config['model'] = selected_model
                    current_config['setup_date'] = datetime.now().isoformat()
                    AgentConfig.save_config(current_config)
                    st.success(f"‚úÖ Model changed to: {model_options[selected_model]}")
                    st.rerun()
            else:
                st.error("‚ùå All models are currently rate limited. Please wait a few minutes before trying again.")
                st.info("üí° You can still use offline analysis features while waiting.")
                
        else:
            st.warning("üî¥ AI Agent Not Configured")
            
            # Initial setup form
            st.markdown("### ‚öôÔ∏è Initial Setup")
            
            api_key_input = st.text_input(
                "OpenRouter API Key",
                type="password",
                value="",
                help="Get your API key from https://openrouter.ai/",
                placeholder="sk-or-v1-..."
            )
            
            if api_key_input:
                if st.button("üß™ Test API Key"):
                    with st.spinner("Testing API connection..."):
                        try:
                            test_agent = create_agent(api_key_input, "qwen/qwen3-235b-a22b:free")
                            if test_agent:
                                st.success("‚úÖ API key is valid!")
                            else:
                                st.error("‚ùå API key test failed")
                        except Exception as e:
                            st.error(f"‚ùå Test failed: {str(e)}")
                
                if st.button("üíæ SAVE API KEY", use_container_width=True):
                    config = {
                        'openrouter_api_key': api_key_input,
                        'model': 'qwen/qwen3-235b-a22b:free',
                        'setup_date': datetime.now().isoformat(),
                        'version': '2.0'
                    }
                    AgentConfig.save_config(config)
                    st.success("‚úÖ Configuration saved successfully!")
                    st.rerun()
    
    except Exception as e:
        st.error(f"AI configuration error: {e}")
    
    st.markdown('</div>', unsafe_allow_html=True)

def render_results_page():
    """Render results page"""
    st.markdown('<div class="glass-card">', unsafe_allow_html=True)
    
    if st.session_state.analysis_results:
        results = st.session_state.analysis_results
        
        st.markdown("### üìä Analysis Results")
        
        # Summary metrics
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Total Packets", f"{results.get('total_packets', 0):,}")
        
        with col2:
            st.metric("Analyzed Packets", f"{results.get('analyzed_packets', 0):,}")
        
        with col3:
            findings_count = len(results.get('findings', []))
            st.metric("Standard Findings", findings_count)
        
        with col4:
            ctf_findings_count = len(results.get('ctf_findings', []))
            st.metric("CTF Findings", ctf_findings_count)
        
        # CTF Challenge Context Display
        if results.get('ctf_context'):
            ctf_ctx = results['ctf_context']
            if ctf_ctx.get('description') or ctf_ctx.get('hints'):
                st.markdown("---")
                st.markdown("### üèÜ CTF Challenge Context")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    if ctf_ctx.get('description'):
                        st.info(f"üìù Challenge Description: {ctf_ctx['description']}")
                
                with col2:
                    if ctf_ctx.get('hints'):
                        st.info(f"üí° Hints & Clues: {ctf_ctx['hints']}")
        
        # Tabbed layout for results - Consolidated and simplified tabs
        st.markdown("---")
        tab_labels = [
            "üîç Findings", "üîÑ Streams", "üó£Ô∏è Sessions", "üß© Protocols", "ü§ñ AI", "üìà Visuals",
            "üïí Timeline", "üóÇÔ∏è Files", "üîÅ Replay", "üõ°Ô∏è Crypto", "üõ†Ô∏è Exploit Workshop", "üí¨ AI Chat", "üì• Export"
        ]
        tabs = st.tabs(tab_labels)
        
        # CTF Specific Analysis Tab
        with tabs[10]:
            if results.get('ctf_analysis') and isinstance(results['ctf_analysis'], dict):
                st.markdown("### üéØ CTF Analysis Results")
                
                # Get CTF-specific data safely
                ctf_analysis = results.get('ctf_analysis', {})
                ctf_findings = ctf_analysis.get('flag_candidates', []) if ctf_analysis else []
                ctf_metadata = ctf_analysis.get('metadata', {}) if ctf_analysis else {}
                
                # Display metrics
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Flags Found", len(ctf_findings))
                with col2:
                    unique_patterns = len(set(f.get('pattern', '') for f in ctf_findings))
                    st.metric("Patterns Identified", unique_patterns)
                with col3:
                    protocol = ctf_metadata.get('primary_protocol', 'N/A')
                    st.metric("Key Protocol", protocol)
                
                # Display flag results
                if ctf_findings:
                    st.markdown("#### üèÅ Flag Candidates")
                    
                    for i, flag in enumerate(ctf_findings):
                        confidence = flag.get('confidence', 70)
                        
                        # Set colors based on confidence
                        bg_color = "#00ff8810" if confidence >= 85 else "#ffaa0010" if confidence >= 70 else "#ff444410"
                        border_color = "#00ff88" if confidence >= 85 else "#ffaa00" if confidence >= 70 else "#ff4444"
                        conf_text = "High Confidence" if confidence >= 85 else "Medium Confidence" if confidence >= 70 else "Potential Match"
                        
                        st.markdown(f"""
                        <div style="background: {bg_color}; border: 1px solid {border_color}; border-radius: 15px; padding: 1.2rem; margin: 1rem 0;">
                            <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 0.8rem;">
                                <div style="font-size: 1.2rem; font-weight: 600; word-break: break-all;">
                                    {flag.get('flag', 'No flag data')}
                                </div>
                                <div style="background: {border_color}44; padding: 0.3rem 0.8rem; border-radius: 15px; font-weight: 600;">
                                    {confidence}% Confidence
                                </div>
                            </div>
                            
                            <div style="color: rgba(255, 255, 255, 0.7); margin-bottom: 0.8rem;">
                                <strong>Pattern:</strong> {flag.get('pattern', 'N/A')} | 
                                <strong>Protocol:</strong> {flag.get('protocol', 'N/A')} | 
                                <strong>Packet:</strong> {flag.get('packet_number', 'N/A')}
                            </div>
                            
                            {f'<div style="background: rgba(0, 245, 255, 0.05); padding: 0.8rem; border-radius: 8px; margin-top: 0.8rem; border-left: 3px solid #00f5ff;">'
                              f'<div style="font-size: 0.9rem; color: #00f5ff; margin-bottom: 0.5rem;">AI Analysis</div>'
                              f'<div>{flag.get("ai_analysis", "")}</div>'
                              f'</div>' if flag.get('ai_analysis') else ''}
                        </div>
                        """, unsafe_allow_html=True)
                else:
                    st.info("üîç No specific flags detected. Try adding challenge context for better CTF analysis.")
                    
        # Flag Reconstruction Results
        with st.expander("üèóÔ∏è Enhanced Flag Reconstruction Results", expanded=True):
            flag_reconstruction = results.get('flag_reconstruction', {})
                        
            if flag_reconstruction.get('reconstructed_flags'):
                st.success(f"üéØ {len(flag_reconstruction['reconstructed_flags'])} flags reconstructed using advanced techniques!")
                            
                # Show reconstruction statistics
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Fragments Analyzed", flag_reconstruction.get('fragments_analyzed', 0))
                with col2:
                    st.metric("Success Rate", f"{flag_reconstruction.get('success_rate', 0)*100:.1f}%")
                with col3:
                    st.metric("Processing Time", f"{flag_reconstruction.get('processing_time', 0):.2f}s")
                            
                # Display each reconstructed flag
                for i, reconstructed_flag in enumerate(flag_reconstruction['reconstructed_flags'], 1):
                    confidence = reconstructed_flag.get('confidence', 0)
                                
                    with st.expander(f"üèóÔ∏è Reconstructed Flag #{i} - {confidence*100:.1f}% Confidence", expanded=True):
                        # Flag display
                        st.markdown("**üéØ Reconstructed Flag:**")
                        st.code(reconstructed_flag['flag'], language="text")
                                    
                        # Reconstruction details
                        col1, col2 = st.columns(2)
                        with col1:
                            st.markdown("**üîß Method:**")
                            st.write(reconstructed_flag.get('reconstruction_method', 'Unknown'))
                                        
                            st.markdown("**üì¶ Source Fragments:**")
                            st.write(f"{len(reconstructed_flag.get('fragments', []))} fragments")
                                    
                        with col2:
                            st.markdown("**üì° Protocols:**")
                            protocols = reconstructed_flag.get('protocols', [])
                            if protocols:
                                st.write(", ".join(protocols))
                            else:
                                st.write("Single protocol")
                                        
                            st.markdown("**üìç Packet Indices:**")
                            packet_indices = reconstructed_flag.get('packet_indices', [])
                            if packet_indices:
                                st.write(f"Packets: {', '.join(map(str, packet_indices[:5]))}{'...' if len(packet_indices) > 5 else ''}")
                            
                # Show reconstruction logs
                if flag_reconstruction.get('reconstruction_logs'):
                    with st.expander("üîß Reconstruction Strategy Details", expanded=False):
                        for log in flag_reconstruction['reconstruction_logs']:
                            if 'error' not in log:
                                st.success(f"‚úÖ {log['strategy']}: {log['flags_found']} flags found (confidence: {log['confidence']*100:.1f}%)")
                            else:
                                st.error(f"‚ùå {log['strategy']}: {log['error']}")
                        
            elif flag_reconstruction.get('error'):
                st.error(f"üö´ Flag reconstruction failed: {flag_reconstruction['error']}")
            else:
                st.info("üîç No distributed flags detected. Flags may be complete within individual packets.")
                            
                # Show reconstruction potential analysis if available
                if hasattr(st.session_state, 'ctf_analyzer') and st.session_state.ctf_analyzer:
                    if st.button("üéØ Analyze Flag Reconstruction Potential"):
                        with st.spinner("Analyzing reconstruction potential..."):
                            try:
                                packet_data_list = [{'data': p.get('data', ''), 'protocol': p.get('protocol', 'Unknown')} 
                                                   for p in results.get('packet_data_list', [])]
                                potential_analysis = st.session_state.ctf_analyzer.analyze_flag_reconstruction_potential(packet_data_list)
                                            
                                st.json(potential_analysis)
                                            
                                if potential_analysis.get('recommendations'):
                                    st.markdown("**üí° Recommendations:**")
                                    for rec in potential_analysis['recommendations']:
                                        st.write(f"‚Ä¢ {rec}")
                                                    
                            except Exception as e:
                                st.error(f"Analysis failed: {str(e)}")
        
        # Add a message if CTF analysis is not available
        if not results.get('ctf_analysis'):
            st.info("CTF analysis results not available. Run analysis with CTF mode enabled.")
        
        # Visuals Tab (Consolidated from Visuals + CTF Visuals)
        with tabs[5]:
            st.markdown("### üìà Visual Analysis")
            
            # Network Flow Visualization
            with st.expander("üåê Network Flow Diagram", expanded=True):
                if st.session_state.visual_analysis:
                    if st.button("üìä Generate Network Flow"):
                        with st.spinner("Creating network flow diagram..."):
                            try:
                                packets = results.get('packets', [])
                                packet_data = results.get('packet_data_list', [])
                                
                                # Ensure we have packet data to work with
                                if not packets and not packet_data:
                                    st.warning("No packet data available for visualization. Please ensure the PCAP file contains valid network traffic.")
                                else:
                                    flow_result = st.session_state.visual_analysis.create_protocol_flow_diagram(packets, packet_data)
                                    
                                    if 'figure' in flow_result:
                                        st.plotly_chart(flow_result['figure'], use_container_width=True)
                                        graph_data = flow_result.get('graph_data', {})
                                        st.info(f"Network contains {graph_data.get('nodes', 0)} hosts and {graph_data.get('edges', 0)} connections")
                                        
                                        # Show protocols found
                                        protocols = graph_data.get('protocols', [])
                                        if protocols:
                                            st.write(f"**Protocols detected:** {', '.join(protocols)}")
                                    elif 'error' in flow_result:
                                        st.error(flow_result['error'])
                                        if 'debug_info' in flow_result:
                                            st.caption(f"Debug info: {flow_result['debug_info']}")
                                    else:
                                        st.error("Failed to create network flow diagram")
                            except Exception as e:
                                st.error(f"Flow diagram generation failed: {str(e)}")
                else:
                    st.info("üîß **Advanced Visualizations Not Available**")
                    st.write("Advanced network flow diagrams require additional modules. Basic analysis data is available:")
                    
                    # Show basic protocol distribution if available
                    if results.get('statistics', {}).get('protocols'):
                        import plotly.express as px
                        protocols = results['statistics']['protocols']
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            fig = px.pie(
                                values=list(protocols.values()),
                                names=list(protocols.keys()),
                                title="Protocol Distribution"
                            )
                            st.plotly_chart(fig, use_container_width=True)
                        
                        with col2:
                            st.write("**Protocol Summary:**")
                            for proto, count in protocols.items():
                                st.write(f"- {proto}: {count} packets")
                    else:
                        st.info("No protocol data available for visualization")
            
            # Timeline Visualization
            with st.expander("üìÖ Communication Timeline", expanded=False):
                if st.session_state.visual_analysis:
                    if st.button("üìÖ Generate Timeline"):
                        with st.spinner("Creating communication timeline..."):
                            try:
                                # Pass the complete results to the timeline generator
                                timeline_result = st.session_state.visual_analysis.create_flag_discovery_timeline(results)
                                
                                if 'figure' in timeline_result:
                                    st.plotly_chart(timeline_result['figure'], use_container_width=True)
                                    stats = timeline_result.get('timeline_stats', {})
                                    total_events = stats.get('total_events', 0)
                                    time_span = stats.get('time_span', 'unknown')
                                    st.info(f"Timeline contains {total_events} events spanning {time_span}")
                                    
                                    # Show event breakdown
                                    event_types = stats.get('event_types', {})
                                    if event_types:
                                        st.write("**Event types:**")
                                        for event_type, count in event_types.items():
                                            st.write(f"- {event_type}: {count}")
                                elif 'error' in timeline_result:
                                    st.error(timeline_result['error'])
                                else:
                                    st.error("Failed to create timeline")
                            except Exception as e:
                                st.error(f"Timeline generation failed: {str(e)}")
                else:
                    st.info("üîß **Advanced Timeline Not Available**")
                    st.write("Advanced timeline visualizations require additional modules. Basic timeline data is available:")
                    
                    # Show basic timeline info if available
                    timeline = results.get('timeline', [])
                    if timeline:
                        st.write(f"**Timeline Summary:** {len(timeline)} events recorded")
                        
                        # Show timeline preview
                        with st.expander("Timeline Preview (First 10 Events)", expanded=False):
                            for i, event in enumerate(timeline[:10]):
                                timestamp = event.get('datetime', 'Unknown time')
                                event_type = event.get('type', 'Unknown')
                                description = event.get('description', 'No description')
                                st.write(f"{i+1}. [{timestamp}] {event_type}: {description[:100]}")
                        
                        st.info("‚Ä¢ Full timeline details are available in the Timeline tab")
                    else:
                        st.info("‚Ä¢ Basic packet information is available in the Timeline tab")
        
        # Exploit Workshop Tab
        with tabs[11]:
            st.markdown("### üõ†Ô∏è Interactive Exploit Workshop")
            
            if st.session_state.exploit_workshop:
                # Difficulty Assessment
                with st.expander("üéØ Challenge Difficulty Assessment", expanded=True):
                    if st.button("üìä Assess Difficulty"):
                        with st.spinner("Assessing challenge difficulty..."):
                            try:
                                difficulty = st.session_state.ui_enhancements.assess_challenge_difficulty(results)
                                
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric("Overall Difficulty", difficulty.get('overall_difficulty', 'Unknown'))
                                with col2:
                                    st.metric("Difficulty Score", f"{difficulty.get('difficulty_score', 0)}/100")
                                with col3:
                                    st.metric("Estimated Time", difficulty.get('estimated_solve_time', 'Unknown'))
                                    
                                # Show recommendations
                                recommendations = difficulty.get('recommended_approach', [])
                                if recommendations:
                                    st.markdown("**Recommended Approach:**")
                                    for rec in recommendations:
                                        st.write(f"‚Ä¢ {rec}")
                                        
                            except Exception as e:
                                st.error(f"Difficulty assessment failed: {str(e)}")
                
                # Vulnerability Analysis
                with st.expander("üîç Vulnerability Analysis", expanded=False):
                    if st.button("üî´ Run Vulnerability Scan"):
                        with st.spinner("Scanning for vulnerabilities..."):
                            try:
                                packets = results.get('packets', [])
                                packet_data = results.get('packet_data_list', [])
                                vuln_results = st.session_state.exploit_workshop.analyze_vulnerabilities(packets, packet_data)
                                
                                vulnerabilities = vuln_results.get('vulnerabilities', [])
                                if vulnerabilities:
                                    st.success(f"Found {len(vulnerabilities)} potential vulnerabilities")
                                    
                                    for vuln in vulnerabilities[:5]:  # Show first 5
                                        severity = vuln.get('severity', 'UNKNOWN')
                                        confidence = vuln.get('confidence', 0)
                                        
                                        severity_color = {
                                            'HIGH': 'üî¥',
                                            'MEDIUM': 'üü°', 
                                            'LOW': 'üü¢'
                                        }.get(severity, '‚ö™')
                                        
                                        st.markdown(f"""
                                        **{severity_color} {vuln.get('type', 'Unknown')}** ({confidence}% confidence)
                                        - **Description:** {vuln.get('description', '')}
                                        - **Location:** {vuln.get('location', '')}
                                        - **Impact:** {vuln.get('potential_impact', '')}
                                        """)
                                        st.markdown("---")
                                else:
                                    st.info("No vulnerabilities detected")
                                    
                            except Exception as e:
                                st.error(f"Vulnerability analysis failed: {str(e)}")
            else:
                st.info("üîß **Exploit Workshop Not Available**")
                st.write("‚Ä¢ Interactive exploit workshop features are not currently initialized")
                st.write("‚Ä¢ This includes vulnerability scanning and difficulty assessment")
                st.write("‚Ä¢ Basic analysis results are still available in other tabs")
        
        # Replay Tab - Enhanced with actual command display
        with tabs[8]:
            st.markdown("### üîÅ Command Replay")
            
            if results.get('replay_commands'):
                commands = results['replay_commands']
                st.success(f"üéØ Found {len(commands)} network commands")
                
                # Filter by protocol
                protocol_filter = st.selectbox(
                    "Filter by Protocol",
                    ["All"] + list(set(cmd.get('protocol', 'Unknown') for cmd in commands))
                )
                
                filtered_commands = commands if protocol_filter == "All" else [
                    cmd for cmd in commands if cmd.get('protocol') == protocol_filter
                ]
                
                if filtered_commands:
                    for i, cmd in enumerate(filtered_commands, 1):
                        protocol = cmd.get('protocol', 'Unknown')
                        command_text = cmd.get('command', '')
                        risk_level = cmd.get('risk_level', 'LOW')
                        packet_num = cmd.get('packet_number', 'N/A')
                        
                        # Risk level colors
                        risk_colors = {
                            'HIGH': 'üî¥',
                            'MEDIUM': 'üü°',
                            'LOW': 'üü¢'
                        }
                        risk_icon = risk_colors.get(risk_level, '‚ö™')
                        
                        with st.expander(f"{risk_icon} {protocol} Command #{i} - Packet {packet_num}", expanded=False):
                            st.code(command_text, language='bash')
                            
                            col1, col2 = st.columns(2)
                            with col1:
                                st.write(f"**Protocol:** {protocol}")
                                st.write(f"**Risk Level:** {risk_level}")
                            with col2:
                                st.write(f"**Source:** {cmd.get('source', 'N/A')}")
                                st.write(f"**Destination:** {cmd.get('destination', 'N/A')}")
                            
                            if cmd.get('description'):
                                st.write(f"**Description:** {cmd['description']}")
                            
                            # Show credentials if found
                            if cmd.get('credentials'):
                                st.warning("üîê **Credentials Detected:**")
                                creds = cmd['credentials']
                                if isinstance(creds, dict):
                                    for key, value in creds.items():
                                        st.write(f"‚Ä¢ **{key}:** `{value}`")
                                else:
                                    st.write(f"‚Ä¢ {creds}")
                else:
                    st.info("No commands match the selected filter")
            else:
                st.info("üîç No network commands detected in the traffic")
                st.write("Supported protocols: FTP, SSH, Telnet, HTTP, SMTP, etc.")
        
        # Crypto Tab (Renamed from Advanced CTF, consolidated with crypto analysis)
        with tabs[9]:
            st.markdown("### üõ°Ô∏è Cryptographic Analysis")
            
            # Comprehensive Crypto Analysis
            crypto_found = False
            
            # 1. JWT Tokens Analysis
            jwt_tokens = results.get('jwt_tokens', [])
            if jwt_tokens:
                crypto_found = True
                with st.expander("üé´ JWT Token Analysis", expanded=True):
                    st.success(f"Found {len(jwt_tokens)} JWT tokens")
                    
                    for i, jwt in enumerate(jwt_tokens[:10]):
                        with st.container():
                            st.markdown(f"**JWT Token #{i+1}** - Packet {jwt.get('packet_index', 0) + 1}")
                            
                            col1, col2 = st.columns(2)
                            with col1:
                                st.markdown("**Header:**")
                                st.json(jwt.get('header', {}), expanded=False)
                            with col2:
                                st.markdown("**Claims:**")
                                st.json(jwt.get('claims', {}), expanded=False)
                            
                            st.markdown(f"**Source:** {jwt.get('src_ip', 'Unknown')} ‚Üí {jwt.get('dst_ip', 'Unknown')} | **Protocol:** {jwt.get('protocol', 'Unknown')}")
                            st.markdown("---")
            
            # 2. Decoded Data Analysis
            decoded_data = results.get('decoded_data', [])
            if decoded_data:
                crypto_found = True
                with st.expander("üîì Decoded Data Analysis", expanded=True):
                    st.success(f"Found {len(decoded_data)} decoded elements")
                    
                    for i, decoded in enumerate(decoded_data[:20]):
                        decoded_text = decoded.get('decoded', '') or decoded.get('result', '')
                        if decoded_text:
                            confidence = decoded.get('confidence', 75)
                            encoding_type = decoded.get('type', 'unknown')
                            
                            with st.container():
                                st.markdown(f"**Decoded Element #{i+1}** - {encoding_type.upper()} - Confidence: {confidence}%")
                                
                                # Show original and decoded
                                col1, col2 = st.columns(2)
                                with col1:
                                    st.markdown("**Original:**")
                                    original = decoded.get('original', 'N/A')
                                    st.code(original[:100] + "..." if len(str(original)) > 100 else str(original), language='text')
                                
                                with col2:
                                    st.markdown("**Decoded:**")
                                    st.code(decoded_text[:200] + "..." if len(decoded_text) > 200 else decoded_text, language='text')
                                
                                # Check if it looks like a flag
                                if 'flag{' in decoded_text.lower() or 'ctf{' in decoded_text.lower():
                                    st.success("üèÜ **Potential Flag Detected!**")
                                
                                st.markdown(f"**Packet:** {decoded.get('packet_index', 0) + 1} | **Protocol:** {decoded.get('protocol', 'Unknown')}")
                                st.markdown("---")
            
            # 3. Encryption/Decryption Attempts
            encryption_attempts = results.get('encryption_attempts', [])
            if encryption_attempts:
                crypto_found = True
                with st.expander("üîê Encryption/Decryption Attempts", expanded=False):
                    st.info(f"Found {len(encryption_attempts)} decryption attempts")
                    
                    for i, attempt in enumerate(encryption_attempts):
                        method = attempt.get('method', 'Unknown')
                        status = attempt.get('status', 'unknown')
                        
                        status_icon = "‚úÖ" if status == 'success' else "‚ùå"
                        
                        with st.expander(f"{status_icon} Attempt #{i+1}: {method}"):
                            st.markdown(f"**Method:** {method}")
                            st.markdown(f"**Status:** {status}")
                            
                            if attempt.get('key'):
                                st.markdown(f"**Key/Password Used:** `{attempt['key']}`")
                            
                            col1, col2 = st.columns(2)
                            with col1:
                                st.markdown("**Input:**")
                                input_data = attempt.get('input', '')
                                st.code(input_data[:100] + "..." if len(input_data) > 100 else input_data, language='text')
                            
                            with col2:
                                st.markdown("**Output:**")
                                output_data = attempt.get('output', '')
                                st.code(output_data[:100] + "..." if len(output_data) > 100 else output_data, language='text')
            
            # 4. Base64 and Encoded Content from Findings
            encoded_findings = [f for f in results.get('findings', []) if 
                              'base64' in f.get('type', '').lower() or 
                              'encoded' in f.get('display_type', '').lower() or
                              'hash' in f.get('type', '').lower()]
            
            if encoded_findings:
                crypto_found = True
                with st.expander("üîç Encoded Content in Findings", expanded=False):
                    st.info(f"Found {len(encoded_findings)} encoded/hash findings")
                    
                    for i, finding in enumerate(encoded_findings[:15]):
                        finding_type = finding.get('display_type', finding.get('type', 'Unknown'))
                        confidence = finding.get('confidence', 0)
                        
                        with st.expander(f"Finding #{i+1}: {finding_type} - {confidence}% confidence"):
                            st.markdown(f"**Type:** {finding_type}")
                            st.markdown(f"**Protocol:** {finding.get('protocol', 'Unknown')}")
                            st.markdown(f"**Packet:** {finding.get('packet_index', 0) + 1}")
                            
                            data = finding.get('data', '')
                            st.markdown("**Data:**")
                            st.code(data[:300] + "..." if len(data) > 300 else data, language='text')
            
            # 5. Hash Analysis
            hash_findings = [f for f in results.get('findings', []) if 'hash' in f.get('type', '').lower()]
            if hash_findings:
                crypto_found = True
                with st.expander("#Ô∏è‚É£ Hash Analysis", expanded=False):
                    st.info(f"Found {len(hash_findings)} hash values")
                    
                    for i, hash_finding in enumerate(hash_findings[:10]):
                        hash_value = hash_finding.get('data', '')
                        hash_length = len(hash_value)
                        
                        # Identify hash type based on length
                        if hash_length == 32:
                            hash_type = "MD5"
                        elif hash_length == 40:
                            hash_type = "SHA-1"
                        elif hash_length == 64:
                            hash_type = "SHA-256"
                        else:
                            hash_type = "Unknown"
                        
                        st.markdown(f"**Hash #{i+1}:** {hash_type} ({hash_length} characters)")
                        st.code(hash_value, language='text')
                        st.caption(f"Packet {hash_finding.get('packet_index', 0) + 1} | Protocol: {hash_finding.get('protocol', 'Unknown')}")
            
            # Display message if no crypto elements found
            if not crypto_found:
                st.info("üîç **No cryptographic elements detected**")
                st.markdown("""
                **What we look for:**
                - üé´ JWT tokens and authentication tokens
                - üîì Base64, Hex, and other encoded data
                - üîê Encrypted content and cipher text
                - #Ô∏è‚É£ Hash values (MD5, SHA-1, SHA-256, etc.)
                - üóùÔ∏è Encryption keys and certificates
                
                **Tips:**
                - Upload PCAP files with authentication traffic
                - Look for web applications using tokens
                - Check for encoded data in HTTP requests/responses
                """)
            
            # Steganography Analysis (moved from Advanced CTF)
            with st.expander("üïµÔ∏è‚Äç‚ôÄÔ∏è Steganography Analysis", expanded=False):
                # Debug information
                detector_available = st.session_state.steganography_detector is not None
                packets_available = results.get('packets') is not None and len(results.get('packets', [])) > 0
                if detector_available and packets_available:
                    if st.button("üîç Run Steganography Detection"):
                        with st.spinner("Analyzing steganography patterns..."):
                            try:
                                packets = results.get('packets', [])
                                packet_data = results.get('packet_data_list', [])
                                stego_results = st.session_state.steganography_detector.analyze_all_steganography(packets, packet_data)
                                
                                if stego_results:
                                    st.success(f"Found {len(stego_results.get('timing_patterns', []))} timing patterns")
                                    st.success(f"Found {len(stego_results.get('size_patterns', []))} size patterns")
                                    st.success(f"Found {len(stego_results.get('covert_channels', []))} covert channels")
                                    
                                    for pattern_type, patterns in stego_results.items():
                                        if isinstance(patterns, list) and patterns:
                                            st.markdown(f"**{pattern_type.replace('_', ' ').title()}:**")
                                            for pattern in patterns[:3]:
                                                st.json(pattern)
                                else:
                                    st.info("No steganography patterns detected")
                            except Exception as e:
                                st.error(f"Steganography analysis failed: {str(e)}")
                else:
                    # Check why steganography detector is not available
                    if not st.session_state.steganography_detector:
                        st.info("üîß **Steganography Detector Not Available**")
                        st.write("‚Ä¢ Advanced steganography analysis features are not currently initialized")
                        if not IMPORTS_OK:
                            st.write("‚Ä¢ Check CTF module imports for initialization errors")
                    elif not results.get('packets'):
                        st.info("üìÑ **Steganography Analysis Ready**")
                        st.write("‚Ä¢ Steganography detector is available and functional")
                        st.write("‚Ä¢ Upload and analyze a PCAP file to enable steganography detection")
                        st.write("‚Ä¢ Supports timing patterns, size patterns, covert channels, and LSB analysis")
                    else:
                        st.info("üöÄ **Steganography Detector Available**")
                        st.write("‚Ä¢ Ready to analyze packet data for hidden information")
                        st.write("‚Ä¢ Click 'Run Steganography Detection' when PCAP is loaded")
            
            # Encoding Chain Analysis (moved from Advanced CTF)
            with st.expander("üîó Encoding Chain Analysis", expanded=False):
                if st.session_state.encoding_analyzer:
                    if st.button("üîó Analyze Encoding Chains"):
                        with st.spinner("Analyzing encoding chains..."):
                            try:
                                packet_data = results.get('packet_data_list', [])
                                encoding_results = st.session_state.encoding_analyzer.analyze_encoding_chains(packet_data)
                                
                                successful_chains = encoding_results.get('successful_decodes', [])
                                if successful_chains:
                                    st.success(f"Successfully decoded {len(successful_chains)} encoding chains")
                                    
                                    for chain in successful_chains[:3]:
                                        with st.container():
                                            st.markdown(f"**Decoded Data:** `{chain.get('decoded_flag', '')}`")
                                            st.markdown(f"**Encoding Chain:** {' ‚Üí '.join(chain.get('encoding_chain', []))}")
                                            st.markdown(f"**Confidence:** {chain.get('confidence', 0)}%")
                                            st.markdown("---")
                                else:
                                    st.info("No encoding chains successfully decoded")
                            except Exception as e:
                                st.error(f"Encoding analysis failed: {str(e)}")
                else:
                    st.info("üîß **Encoding Chain Analyzer Available**")
                    st.write("‚Ä¢ Click 'Analyze Encoding Chains' to detect multi-layer encoded data")
                    st.write("‚Ä¢ Supports Base64, Hex, ROT13, URL encoding, and custom chains")
                    st.write("‚Ä¢ Automatically reconstructs flags from encoding layers")
        
        # Export Tab (Consolidated from CTF Report + Export)
        with tabs[11]:
            st.markdown("### üì• Export & Reporting")
            
            # Quick Export Section
            with st.expander("üìÑ Quick Export", expanded=True):
                col1, col2 = st.columns(2)
                
                with col1:
                    export_format = st.selectbox(
                        "Export Format",
                        ["json", "csv", "html"],
                        help="Choose the format for your analysis results"
                    )
                
                with col2:
                    include_raw_data = st.checkbox(
                        "Include Raw Packet Data",
                        value=False,
                        help="Include detailed packet information (larger file size)"
                    )
                
                if st.button("üì• Export Results", use_container_width=True):
                    try:
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        filename = f"flagsniff_results_{timestamp}.{export_format}"
                        
                        # Prepare export data
                        export_data = {
                            'summary': {
                                'total_packets': results.get('total_packets', 0),
                                'findings_count': len(results.get('findings', [])),
                                'analysis_time': timestamp
                            },
                            'findings': results.get('findings', []),
                            'statistics': results.get('statistics', {}),
                            'ai_analysis': results.get('ai_analysis', {}) if results.get('ai_status') == 'success' else None
                        }
                        
                        if include_raw_data:
                            export_data['packet_data'] = results.get('packet_data_list', [])
                        
                        if export_format == 'json':
                            import json
                            export_content = json.dumps(export_data, indent=2)
                            mime_type = "application/json"
                        elif export_format == 'csv':
                            import pandas as pd
                            findings_df = pd.DataFrame(results.get('findings', []))
                            export_content = findings_df.to_csv(index=False)
                            mime_type = "text/csv"
                        else:  # html
                            export_content = f"""
                            <html><head><title>FlagSniff Analysis Report</title></head>
                            <body>
                                <h1>FlagSniff Analysis Report</h1>
                                <h2>Summary</h2>
                                <p>Total Packets: {results.get('total_packets', 0)}</p>
                                <p>Findings: {len(results.get('findings', []))}</p>
                                <h2>Findings</h2>
                                {''.join([f'<div><strong>{f.get("type", "Unknown")}</strong>: {f.get("data", "")}</div>' for f in results.get('findings', [])])}
                            </body></html>
                            """
                            mime_type = "text/html"
                        
                        st.download_button(
                            label=f"üíæ Download {export_format.upper()}",
                            data=export_content,
                            file_name=filename,
                            mime=mime_type,
                            use_container_width=True
                        )
                        
                        st.success(f"‚úÖ Export ready! File: {filename}")
                        
                    except Exception as e:
                        st.error(f"‚ùå Export failed: {str(e)}")
            
            # Automated CTF Report Section
            with st.expander("üìã CTF Analysis Report", expanded=False):
                if st.session_state.automated_reporting:
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        report_format = st.selectbox(
                            "Report Format",
                            ["json", "markdown", "html"],
                            help="Choose the output format for your CTF report",
                            key="ctf_report_format"
                        )
                    
                    with col2:
                        include_writeup = st.checkbox(
                            "Include CTF Writeup",
                            value=True,
                            help="Generate step-by-step solution writeup"
                        )
                    
                    if st.button("üì¶ Generate CTF Report"):
                        with st.spinner("Generating comprehensive CTF report..."):
                            try:
                                user_progress = {
                                    'time_spent': 30,
                                    'action_counts': {'analyze_packet': 10, 'test_exploit': 2},
                                    'stage': 'completion'
                                }
                                
                                challenge_context = {
                                    'name': 'PCAP Analysis Challenge',
                                    'type': 'forensics',
                                    'description': 'Network traffic analysis challenge',
                                    'hints': ['Check for hidden data', 'Look at protocol headers']
                                }
                                
                                report = st.session_state.automated_reporting.generate_comprehensive_report(
                                    results, user_progress, challenge_context, include_writeup
                                )
                                
                                export_result = st.session_state.automated_reporting.export_report(report, report_format)
                                
                                if export_result.get('success'):
                                    st.success(f"Report generated successfully in {report_format.upper()} format!")
                                    
                                    st.download_button(
                                        label=f"Download {report_format.upper()} Report",
                                        data=export_result['content'],
                                        file_name=export_result['filename'],
                                        mime=export_result['mime_type']
                                    )
                                    
                                    with st.expander("Report Preview", expanded=False):
                                        if report_format == 'json':
                                            st.json(report)
                                        else:
                                            st.code(export_result['content'][:1000] + "..." if len(export_result['content']) > 1000 else export_result['content'])
                                else:
                                    st.error(f"Failed to generate report: {export_result.get('error')}")
                                    
                            except Exception as e:
                                st.error(f"Report generation failed: {str(e)}")
                else:
                    st.info("üîß **Automated Reporting Not Available**")
                    st.write("‚Ä¢ Use the Quick Export section above for basic result export")
                    st.write("‚Ä¢ Manual analysis results are available in other tabs")

        # Findings Tab
        with tabs[0]:
            # Advanced Steganography Results
            if results.get('steganography_analysis'):
                st.markdown("### üîç Advanced Steganography Analysis")
                stego_analysis = results['steganography_analysis']
                
                # Display steganography summary
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("Image LSB Findings", len(stego_analysis.get('image_steganography', [])))
                with col2:
                    st.metric("Audio Stego Findings", len(stego_analysis.get('audio_steganography', [])))
                with col3:
                    st.metric("File Signature Issues", len(stego_analysis.get('file_signature_analysis', [])))
                with col4:
                    st.metric("Timing Patterns", len(stego_analysis.get('timing_patterns', [])))
                
                # Display advanced steganography findings
                all_stego_findings = (
                    stego_analysis.get('image_steganography', []) +
                    stego_analysis.get('audio_steganography', []) +
                    stego_analysis.get('file_signature_analysis', []) +
                    stego_analysis.get('timing_patterns', []) +
                    stego_analysis.get('size_patterns', [])
                )
                
                if all_stego_findings:
                    st.markdown("#### üéØ Steganography Discoveries")
                    for i, finding in enumerate(all_stego_findings):
                        confidence = finding.get('confidence', 50)
                        finding_type = finding.get('type', 'unknown')
                        
                        # Color coding based on confidence and type
                        if confidence >= 85:
                            border_color = "#00ff88"
                            bg_color = "rgba(0, 255, 136, 0.1)"
                        elif confidence >= 70:
                            border_color = "#ffaa00"
                            bg_color = "rgba(255, 170, 0, 0.1)"
                        else:
                            border_color = "#ff4444"
                            bg_color = "rgba(255, 68, 68, 0.1)"
                        
                        # Icon based on finding type
                        type_icons = {
                            'image_lsb': 'üñºÔ∏è',
                            'image_metadata': 'üìù',
                            'audio_steganography': 'üéµ',
                            'multiple_file_signatures': 'üìÅ',
                            'hidden_file_after_nulls': 'üîí',
                            'appended_file': 'üìé',
                            'timing_binary': '‚è±Ô∏è',
                            'timing_morse': 'üì°',
                            'size_binary': 'üìè'
                        }
                        
                        icon = type_icons.get(finding_type, 'üîç')
                        
                        st.markdown(f"""
                        <div style="background: {bg_color}; border: 1px solid {border_color}; border-radius: 15px; padding: 1.5rem; margin: 1rem 0; border-left: 4px solid {border_color};">
                            <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 1rem;">
                                <div style="font-weight: 600; font-size: 1.1rem;">
                                    {icon} {finding.get('method', 'Steganography Detection')}
                                </div>
                                <div style="background: {border_color}44; padding: 0.3rem 0.8rem; border-radius: 15px; font-size: 0.8rem; font-weight: 600;">
                                    {confidence}% confidence
                                </div>
                            </div>
                            {f'<div style="font-family: monospace; background: rgba(0, 0, 0, 0.2); padding: 1rem; border-radius: 8px; margin: 0.5rem 0; word-break: break-all;"><strong>Data:</strong> {finding.get("data", "N/A")[:200]}{"..." if len(finding.get("data", "")) > 200 else ""}</div>' if finding.get('data') else ''}
                            <div style="font-size: 0.9rem; color: rgba(255, 255, 255, 0.7); margin-top: 0.8rem;">
                                <strong>Evidence:</strong> {finding.get('evidence', 'No evidence details')}<br>
                                <strong>Pattern:</strong> {finding.get('pattern', 'No pattern details')}
                            </div>
                        </div>
                        """, unsafe_allow_html=True)
                
                st.markdown("---")
            
            # Advanced CTF Solver Results
            if results.get('ctf_solver_analysis'):
                st.markdown("### üéØ Advanced CTF Challenge Solver")
                solver_analysis = results['ctf_solver_analysis']
                
                # Display solver summary
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("Challenge Type", solver_analysis.get('challenge_type', 'Unknown'))
                with col2:
                    st.metric("Flags Found", len(solver_analysis.get('flags_found', [])))
                with col3:
                    st.metric("Techniques Used", len(solver_analysis.get('techniques_used', [])))
                with col4:
                    solving_time = solver_analysis.get('solving_time', 0)
                    st.metric("Solving Time", f"{solving_time:.1f}s")
                
                # Display solving process
                if solver_analysis.get('solving_steps'):
                    with st.expander("üîß Solving Process", expanded=True):
                        for i, step in enumerate(solver_analysis['solving_steps'], 1):
                            if 'error' in step.lower():
                                st.error(f"Step {i}: {step}")
                            elif 'found flag' in step.lower():
                                st.success(f"‚úÖ Step {i}: {step}")
                            else:
                                st.info(f"Step {i}: {step}")
                
                # Display found flags
                if solver_analysis.get('flags_found'):
                    st.markdown("#### üèÜ Automatically Discovered Flags")
                    for i, flag in enumerate(solver_analysis['flags_found'], 1):
                        st.markdown(f"""
                        <div style="background: linear-gradient(135deg, rgba(0, 255, 136, 0.15) 0%, rgba(0, 245, 255, 0.15) 100%); border: 2px solid #00ff88; border-radius: 15px; padding: 1.5rem; margin: 1rem 0; border-left: 6px solid #00ff88;">
                            <div style="font-weight: 600; font-size: 1.2rem; margin-bottom: 1rem;">
                                üèÜ Auto-Solved Flag #{i}
                            </div>
                            <div style="font-family: monospace; background: rgba(0, 0, 0, 0.3); padding: 1.2rem; border-radius: 8px; font-size: 1.1rem; font-weight: 600; color: #00ff88;">
                                {flag}
                            </div>
                        </div>
                        """, unsafe_allow_html=True)
                
                # Display techniques used
                if solver_analysis.get('techniques_used'):
                    with st.expander("üõ†Ô∏è Techniques Applied", expanded=False):
                        techniques = solver_analysis['techniques_used']
                        for technique in techniques:
                            st.write(f"‚Ä¢ {technique}")
                
                # Display recommendations
                if solver_analysis.get('recommendations'):
                    with st.expander("üí° Solver Recommendations", expanded=True):
                        recommendations = solver_analysis['recommendations']
                        for rec in recommendations:
                            if 'no flags found' in rec.lower():
                                st.warning(f"‚ö†Ô∏è {rec}")
                            elif 'successfully found' in rec.lower():
                                st.success(f"‚úÖ {rec}")
                            else:
                                st.info(f"üí° {rec}")
                
                st.markdown("---")
            
            # Standard Findings Display
            if results.get('findings'):
                st.markdown("### üîç Detected Findings")
                
                # Debug information about findings
                total_findings = len(results['findings'])
                finding_types = {}
                confidence_ranges = {'0-20': 0, '21-40': 0, '41-60': 0, '61-80': 0, '81-100': 0}
                
                for finding in results['findings']:
                    # Count by type
                    ftype = finding.get('display_type', finding.get('type', 'Unknown'))
                    finding_types[ftype] = finding_types.get(ftype, 0) + 1
                    
                    # Count by confidence range
                    conf = finding.get('confidence', 50)
                    if conf <= 20:
                        confidence_ranges['0-20'] += 1
                    elif conf <= 40:
                        confidence_ranges['21-40'] += 1
                    elif conf <= 60:
                        confidence_ranges['41-60'] += 1
                    elif conf <= 80:
                        confidence_ranges['61-80'] += 1
                    else:
                        confidence_ranges['81-100'] += 1
                
                # Display summary
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown(f"**Total Findings:** {total_findings}")
                    if finding_types:
                        st.markdown("**By Type:**")
                        for ftype, count in finding_types.items():
                            st.markdown(f"- {ftype}: {count}")
                
                with col2:
                    st.markdown("**Confidence Distribution:**")
                    for range_label, count in confidence_ranges.items():
                        if count > 0:
                            st.markdown(f"- {range_label}%: {count}")
                
                min_conf = st.slider("Minimum confidence to display", 0, 100, 20, key="findings_min_conf")
                filtered_findings = [f for f in results['findings'] if f.get('confidence', 90) >= min_conf]
                
                if not filtered_findings:
                    st.warning(f"No findings at or above {min_conf}% confidence. Try lowering the threshold.")
                    # Show some examples of what's available at lower confidence
                    low_conf_examples = [f for f in results['findings'][:5]]
                    if low_conf_examples:
                        st.markdown("**Sample findings below threshold:**")
                        for f in low_conf_examples:
                            st.markdown(f"- {f.get('display_type', 'Unknown')}: {f.get('confidence', 0)}% confidence")
                else:
                    st.success(f"Showing {len(filtered_findings)} findings above {min_conf}% confidence")
                

                # Show AI Analysis Results Separately if Available
                if results.get('ai_analysis') and results['ai_analysis'].get('ai_analysis'):
                    ai_analysis = results['ai_analysis']['ai_analysis']
                    
                    st.markdown("---")
                    st.markdown("### ü§ñ AI Analysis Results")
                    
                    # Show AI enhanced findings
                    if ai_analysis.get('enhanced_findings'):
                        st.markdown("**üéØ AI Discovered Findings:**")
                        for i, ai_finding in enumerate(ai_analysis['enhanced_findings'], 1):
                            if isinstance(ai_finding, dict):
                                flag_data = ai_finding.get('finding', ai_finding.get('data', ''))
                                confidence = ai_finding.get('confidence', 0)
                                explanation = ai_finding.get('explanation', '')
                                
                                # Determine if this is a flag
                                is_flag = 'flag' in flag_data.lower() and '{' in flag_data and '}' in flag_data
                                icon = 'üèÜ' if is_flag else 'ü§ñ'
                                border_color = "#00ff88" if confidence >= 90 else "#ffaa00" if confidence >= 70 else "#ff4444"
                                
                                st.markdown(f"""
                                <div style="background: linear-gradient(135deg, rgba(0, 255, 136, 0.1) 0%, rgba(0, 245, 255, 0.1) 100%); border: 2px solid {border_color}; border-radius: 15px; padding: 1.5rem; margin: 1rem 0; border-left: 6px solid {border_color};">
                                    <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 1rem;">
                                        <div style="font-weight: 600; font-size: 1.2rem;">
                                            {icon} AI Discovery #{i}
                                        </div>
                                        <div style="background: rgba(0, 245, 255, 0.3); padding: 0.4rem 1rem; border-radius: 15px; font-size: 0.9rem; font-weight: 600;">
                                            {confidence}% confidence
                                        </div>
                                    </div>
                                    <div style="font-family: monospace; background: rgba(0, 0, 0, 0.2); padding: 1.2rem; border-radius: 8px; margin: 0.8rem 0; font-size: 1.1rem; font-weight: 600;">
                                        {flag_data}
                                    </div>
                                    <div style="background: rgba(0, 245, 255, 0.05); padding: 1rem; border-radius: 8px; margin-top: 0.8rem; border-left: 3px solid #00f5ff;">
                                        <div style="font-size: 0.9rem; color: #00f5ff; margin-bottom: 0.5rem; font-weight: 600;">AI Explanation</div>
                                        <div style="font-style: italic;">{explanation}</div>
                                    </div>
                                </div>
                                """, unsafe_allow_html=True)
                    
                    # Show security assessment
                    if ai_analysis.get('security_assessment'):
                        with st.expander("üîí Security Assessment", expanded=False):
                            sec_assessment = ai_analysis['security_assessment']
                            if sec_assessment.get('implications'):
                                st.markdown("**Implications:**")
                                st.write(sec_assessment['implications'])
                            if sec_assessment.get('attack_vectors'):
                                st.markdown("**Potential Attack Vectors:**")
                                attack_vectors = sec_assessment['attack_vectors']
                                
                                # Handle different attack vector formats
                                if isinstance(attack_vectors, list):
                                    for vector in attack_vectors:
                                        if isinstance(vector, str):
                                            st.write(f"‚Ä¢ {vector}")
                                        else:
                                            st.write(f"‚Ä¢ {str(vector)}")
                                elif isinstance(attack_vectors, str):
                                    # If attack_vectors is a string, display it directly
                                    st.write(attack_vectors)
                                else:
                                    # Fallback for other formats
                                    st.write(str(attack_vectors))
                    
                    # Show CTF insights
                    if ai_analysis.get('ctf_insights'):
                        with st.expander("üéØ CTF Insights", expanded=False):
                            ctf_insights = ai_analysis['ctf_insights']
                            if ctf_insights.get('observations'):
                                st.markdown("**Observations:**")
                                st.write(ctf_insights['observations'])
                            if ctf_insights.get('strategies'):
                                st.markdown("**Recommended Strategies:**")
                                strategies = ctf_insights['strategies']
                                
                                # Handle different strategy formats
                                if isinstance(strategies, list):
                                    for strategy in strategies:
                                        if isinstance(strategy, str):
                                            st.write(f"‚Ä¢ {strategy}")
                                        else:
                                            st.write(f"‚Ä¢ {str(strategy)}")
                                elif isinstance(strategies, str):
                                    # If strategies is a string, display it directly
                                    st.write(strategies)
                                else:
                                    # Fallback for other formats
                                    st.write(str(strategies))
                            if ctf_insights.get('challenge_themes'):
                                st.markdown("**Challenge Themes:**")
                                themes = ctf_insights['challenge_themes']
                                # Handle both string and list formats
                                if isinstance(themes, str):
                                    # If it's a string, display it directly
                                    st.write(themes)
                                elif isinstance(themes, list):
                                    # If it's a list, join with commas
                                    themes_text = ", ".join(themes)
                                    st.write(themes_text)
                                else:
                                    # Fallback for other formats
                                    st.write(str(themes))
                    
                    # Show recommendations
                    if ai_analysis.get('recommendations'):
                        with st.expander("üí° AI Recommendations", expanded=False):
                            recommendations = ai_analysis['recommendations']
                            
                            # Handle different recommendation formats
                            if isinstance(recommendations, list):
                                for rec in recommendations:
                                    if isinstance(rec, dict):
                                        priority = rec.get('priority', 'Medium')
                                        action = rec.get('action', str(rec))
                                        priority_color = {'High': 'üî¥', 'Medium': 'üü°', 'Low': 'üü¢'}.get(priority, 'üîµ')
                                        st.write(f"{priority_color} **{priority}**: {action}")
                                    elif isinstance(rec, str):
                                        st.write(f"‚Ä¢ {rec}")
                                    else:
                                        st.write(f"‚Ä¢ {str(rec)}")
                            elif isinstance(recommendations, str):
                                # If recommendations is a string, display it directly
                                st.write(recommendations)
                            else:
                                # Fallback for other formats
                                st.write(str(recommendations))
                
                # MOST IMPORTANT: Show AI Findings in JSON Format (as requested by user)
                if results.get('ai_findings'):
                    st.markdown("---")
                    st.markdown("### ü§ñ AI Findings (JSON Format)")
                    st.markdown("‚ÑπÔ∏è **This is the JSON format display you were looking for!**")
                    
                    ai_findings = results['ai_findings']
                    if isinstance(ai_findings, list) and ai_findings:
                        # Sort by confidence (important results on top as requested)
                        sorted_ai_findings = sorted(ai_findings, key=lambda x: x.get('confidence', 0), reverse=True)
                        
                        st.markdown(f"**Found {len(sorted_ai_findings)} AI Discoveries (sorted by confidence, important results first):**")
                        
                        for i, ai_finding in enumerate(sorted_ai_findings, 1):
                            if isinstance(ai_finding, dict):
                                confidence = ai_finding.get('confidence', 0)
                                flag_candidate = ai_finding.get('flag_candidate', ai_finding.get('data', 'No data'))
                                
                                # Priority classification
                                if confidence >= 90:
                                    priority = "üèÜ VERY HIGH PRIORITY"
                                    expanded = True
                                elif confidence >= 80:
                                    priority = "‚≠ê HIGH PRIORITY"
                                    expanded = True  
                                elif confidence >= 70:
                                    priority = "üìã MEDIUM PRIORITY"
                                    expanded = i <= 5
                                else:
                                    priority = "‚ö†Ô∏è LOW PRIORITY"
                                    expanded = False
                                
                                with st.expander(f"{priority} - AI Finding #{i} ({confidence}% confidence)", expanded=expanded):
                                    # Display finding data prominently
                                    st.markdown("**üéØ Finding Data:**")
                                    st.code(flag_candidate, language="text")
                                    
                                    # Display full JSON structure as requested
                                    st.markdown("**üìä Complete JSON Structure:**")
                                    st.json(ai_finding)
                                    
                                    # Additional analysis if available
                                    if ai_finding.get('reasoning'):
                                        st.markdown("**üß† AI Reasoning:**")
                                        st.info(ai_finding['reasoning'])
                                    
                                    if ai_finding.get('poc'):
                                        st.markdown("**üîß Proof of Concept:**")
                                        st.code(ai_finding['poc'], language="text")
                            else:
                                with st.expander(f"üîç AI Finding #{i}", expanded=i <= 3):
                                    st.code(str(ai_finding), language="text")
                    
                    elif isinstance(ai_findings, dict):
                        st.markdown("**AI Analysis Structure:**")
                        st.json(ai_findings)
                    
                    else:
                        st.info("AI findings available but in unexpected format.")
                        st.code(str(ai_findings), language="text")
                for i, finding in enumerate(filtered_findings[:20]):
                    confidence = finding.get('confidence', 50)
                    if confidence >= 80:
                        border_color = "#00ff88"
                    elif confidence >= 60:
                        border_color = "#ffaa00"
                    else:
                        border_color = "#ff4444"
                    st.markdown(f"""
                    <div style="background: linear-gradient(135deg, rgba(0, 255, 136, 0.08) 0%, rgba(0, 245, 255, 0.08) 100%); border: 1px solid {border_color}; border-radius: 15px; padding: 1.5rem; margin: 1rem 0; border-left: 4px solid {border_color};">
                        <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 1rem;">
                            <div style="font-weight: 600; font-size: 1.1rem;">
                                {finding.get('icon', 'üîç')} {finding.get('display_type', 'Finding')}
                            </div>
                            <div style="background: rgba(0, 245, 255, 0.2); padding: 0.3rem 0.8rem; border-radius: 15px; font-size: 0.8rem;">
                                {confidence}% confidence
                            </div>
                        </div>
                        <div style="font-family: monospace; background: rgba(0, 0, 0, 0.1); padding: 1rem; border-radius: 8px; margin: 0.5rem 0;">
                            {finding.get('data', 'No data')[:300]}{'...' if len(finding.get('data', '')) > 300 else ''}
                        </div>
                        <div style="font-size: 0.9rem; color: rgba(255, 255, 255, 0.7);">
                            <strong>Protocol:</strong> {finding.get('protocol', 'Unknown')} | 
                            <strong>Source:</strong> {finding.get('src_ip', finding.get('src', 'N/A'))} ‚Üí {finding.get('dst_ip', finding.get('dst', 'N/A'))}
                        </div>
                    </div>
                    """, unsafe_allow_html=True)
                    if finding.get('protocol') == 'HTTP':
                        with st.expander(f"HTTP Details for Finding #{i+1}"):
                            if finding.get('http_headers'):
                                st.markdown("**HTTP Headers:**")
                                st.code(finding['http_headers'], language="http")
                            if finding.get('http_body'):
                                st.markdown("**HTTP Body:**")
                                st.code(finding['http_body'], language="text")
                            if finding.get('http_method') or finding.get('http_path'):
                                st.markdown(f"**Request:** {finding.get('http_method', '')} {finding.get('http_path', '')}")
                            if finding.get('credentials'):
                                st.markdown("**Extracted Credentials:**")
                                for cred in finding['credentials']:
                                    st.json(cred)
                    if finding.get('decoded'):
                        with st.expander(f"Decoded/Decrypted Data for Finding #{i+1}"):
                            st.markdown("**Decoded/Decrypted Data:**")
                            st.code(finding['decoded'], language="text")
                            if finding.get('decode_method'):
                                st.markdown(f"**Method:** {finding['decode_method']}")
                    if finding.get('stream_id') or finding.get('tcp_stream'):
                        with st.expander(f"Stream Context for Finding #{i+1}"):
                            st.markdown(f"**Stream ID:** {finding.get('stream_id', finding.get('tcp_stream', 'N/A'))}")
                            if finding.get('stream_data'):
                                st.code(finding['stream_data'][:1000], language="text")
                    if finding.get('flag_chunks'):
                        with st.expander(f"Flag Reassembly for Finding #{i+1}"):
                            st.markdown("**Flag Chunks:**")
                            for chunk in finding['flag_chunks']:
                                st.code(chunk, language="text")
                            if finding.get('reassembled_flag'):
                                st.success(f"Reassembled Flag: {finding['reassembled_flag']}")
                    # PoC / Reproduction details
                    if finding.get('poc'):
                        with st.expander(f"üîß PoC & Reproduction for Finding #{i+1}"):
                            poc = finding.get('poc') or {}
                            where = poc.get('where_found') or {}
                            steps = poc.get('extraction_steps') or []
                            if where:
                                st.markdown("**Where Found:**")
                                st.write(
                                    f"- Frame: {where.get('frame_number', (finding.get('packet_index', 0) or 0) + 1)}  "
                                    f"| Packet Index: {where.get('packet_index', finding.get('packet_index',''))}  "
                                    f"| Protocol: {where.get('protocol', finding.get('protocol','Unknown'))}  "
                                )
                                st.write(f"- Source ‚Üí Dest: {where.get('src_ip', finding.get('src_ip',''))} ‚Üí {where.get('dst_ip', finding.get('dst_ip',''))}")
                            if steps:
                                st.markdown("**Extraction Steps:**")
                                for si, step in enumerate(steps, 1):
                                    st.write(f"{si}. Method: `{step.get('method','')}`")
                                    cmd = step.get('command')
                                    if cmd:
                                        st.code(cmd, language='bash')

        # Streams Tab
        with tabs[1]:
            st.markdown("### üîÑ Reconstructed Streams")
            if results.get('reconstructed_streams'):
                hide_binary = st.checkbox("Hide binary/TLS-like streams", value=True, key="hide_binary_streams")
                view_mode = st.radio("View mode", ["Auto", "Printable", "Hex"], index=0, horizontal=True, key="stream_view_mode")
                
                stream_count = 0
                for stream_id, stream in results['reconstructed_streams'].items():
                    data = stream.get('data', b'')
                    if isinstance(data, str):
                        try:
                            data_bytes = data.encode('utf-8', errors='ignore')
                        except Exception:
                            data_bytes = data
                    else:
                        data_bytes = data or b''
                    
                    if not data_bytes:
                        continue
                        
                    printable = sum(1 for b in data_bytes[:2000] if 32 <= (b if isinstance(b, int) else ord(b)) < 127)
                    ratio = (printable / max(len(data_bytes[:2000]), 1)) if data_bytes else 0
                    if hide_binary and ratio < 0.2:
                        continue
                    
                    stream_count += 1
                    def to_hex_dump(b):
                        lines = []
                        for i in range(0, min(len(b), 1024), 16):
                            chunk = b[i:i+16]
                            hex_part = ' '.join(f"{x:02x}" for x in chunk)
                            asc_part = ''.join(chr(x) if 32 <= x < 127 else '.' for x in chunk)
                            lines.append(f"{i:08x}  {hex_part:<47}  {asc_part}")
                        return "\n".join(lines)
                    if view_mode == "Hex":
                        preview = to_hex_dump(data_bytes)
                    elif view_mode == "Printable":
                        preview = ''.join(chr(x) if 32 <= x < 127 else '.' for x in data_bytes[:2000])
                    else:  # Auto
                        preview = ''.join(chr(x) if 32 <= x < 127 else '.' for x in data_bytes[:2000]) if ratio < 0.4 else (data if isinstance(data, str) else data_bytes[:2000].decode('utf-8', errors='ignore'))
                    with st.expander(f"Stream {stream_id}"):
                        st.markdown(f"**Source:** {stream.get('src_ip', 'N/A')} ‚Üí {stream.get('dst_ip', 'N/A')}")
                        st.markdown(f"**Protocol:** {stream.get('protocol', 'TCP')}")
                        st.code(preview, language="text")
                        if stream.get('http_requests') or stream.get('http_responses'):
                            st.markdown("**HTTP Messages in Stream:**")
                            if stream.get('http_requests'):
                                for req in stream['http_requests']:
                                    st.code(req, language="http")
                            if stream.get('http_responses'):
                                for resp in stream['http_responses']:
                                    st.code(resp, language="http")
                
                if stream_count == 0:
                    if results.get('reconstructed_streams'):
                        st.info("All streams are hidden by current filters. Try adjusting the 'Hide binary/TLS-like streams' option.")
                    else:
                        st.info("No streams were reconstructed from the traffic.")
            else:
                st.info("No TCP streams found in the capture. This may indicate UDP-only traffic or analysis issues.")

        # Sessions Tab
        with tabs[2]:
            st.markdown("### üó£Ô∏è Session / Conversation Views")
            session_views = results.get('session_views') or {}
            if session_views:
                for proto, sessions in session_views.items():
                    with st.expander(f"{proto} Sessions ({len(sessions)})", expanded=False):
                        for sess_id, messages in sessions.items():
                            st.markdown(f"**Session:** `{sess_id}`")
                            for msg in messages:
                                # Ensure msg is a dict
                                if not isinstance(msg, dict):
                                    msg = {'content': str(msg), 'timestamp': '', 'direction': 'UNKNOWN'}
                                    
                                # Get message details with safe defaults
                                ts = msg.get('timestamp', '')
                                direction = msg.get('direction', 'UNKNOWN')
                                content = msg.get('content', '')
                                msg_type = msg.get('type', 'data')
                                
                                # Format the message based on its type
                                if msg_type in ['request', 'response']:
                                    st.write(f"[{ts}] **{direction}**")
                                else:
                                    st.write(f"[{ts}] {direction}")
                                    
                                # Display content safely
                                try:
                                    if isinstance(content, (dict, list)):
                                        st.json(content)
                                    else:
                                        st.code(str(content)[:2000], language="text")
                                except Exception as e:
                                    st.error(f"Error displaying content: {str(e)}")
                                    st.code(str(content)[:100] + "...", language="text")
                            st.markdown("---")
            else:
                # Fallback: raw sessions summary if available
                raw_sessions = results.get('sessions') or {}
                if raw_sessions:
                    st.info("No reconstructed conversations available. Showing raw session summary.")
                    for s_type, s_map in raw_sessions.items():
                        st.write(f"- {s_type}: {len(s_map)} sessions")
                else:
                    st.warning("No session data available. Run analysis on a PCAP with FTP/SMTP/IRC/chat traffic or enable parsing options.")

        # Protocols Tab
        with tabs[3]:
            st.markdown("### üß© Protocol-Specific Details")
            proto_details = results.get('protocol_details') or []
            if proto_details:
                for item in proto_details[:50]:
                    proto = item.get('protocol', 'Unknown')
                    sni = item.get('sni')
                    summary = item.get('summary')
                    src = item.get('src_ip', '')
                    dst = item.get('dst_ip', '')
                    if sni:
                        st.write(f"- [{proto}] {src} ‚Üí {dst} | SNI: `{sni}`")
                    elif summary:
                        st.write(f"- [{proto}] {src} ‚Üí {dst} | {summary}")
                    else:
                        st.write(f"- [{proto}] {src} ‚Üí {dst}")
            else:
                # Quick fallback summary by protocol counts
                findings = results.get('findings', [])
                if findings:
                    from collections import Counter
                    counts = Counter([f.get('protocol','Unknown') for f in findings])
                    st.info("No decoder details recorded. Showing protocol counts from findings.")
                    for proto, count in counts.most_common():
                        st.write(f"- {proto}: {count}")
                else:
                    st.warning("No protocol details available. Ensure analysis completed and protocol-specific parsing is enabled.")

        # AI Tab
        with tabs[4]:
            st.markdown("### ü§ñ AI Analysis & Hints")
            
            # DEBUG: Show comprehensive AI analysis debugging information
            with st.expander("üîç Debug AI Analysis Status", expanded=True):  # Changed to expanded=True
                st.markdown("**üìä AI Analysis Debugging Information:**")
                
                # Show all AI-related keys in results
                ai_keys = [k for k in results.keys() if 'ai' in k.lower()]
                st.write(f"üîë AI-related keys in results: {ai_keys}")
                
                # Show detailed status
                ai_status = results.get('ai_status', 'Not set')
                ai_findings = results.get('ai_findings', [])
                ai_suggestions = results.get('ai_suggestions', [])
                ai_error = results.get('ai_error', 'None')
                
                st.write(f"üè∑Ô∏è AI Status: `{ai_status}`")
                st.write(f"üîç AI Findings Count: {len(ai_findings) if isinstance(ai_findings, list) else 'Not a list'}")
                st.write(f"üí° AI Suggestions Count: {len(ai_suggestions) if isinstance(ai_suggestions, list) else 'Not a list'}")
                st.write(f"‚ö†Ô∏è AI Error: `{ai_error}`")
                
                # ENHANCED: Show why AI analysis results might not be showing
                st.markdown("---")
                st.markdown("**ü§î Why might AI results not be showing?**")
                
                # Check condition for AI display
                has_ai_status = bool(results.get('ai_status'))
                has_ai_findings = bool(results.get('ai_findings'))
                has_ai_suggestions = bool(results.get('ai_suggestions'))
                display_condition = has_ai_status or has_ai_findings or has_ai_suggestions
                
                st.write(f"‚úÖ Has AI Status: {has_ai_status} (`{ai_status}`)")
                st.write(f"‚úÖ Has AI Findings: {has_ai_findings} (count: {len(ai_findings) if isinstance(ai_findings, list) else 0})")
                st.write(f"‚úÖ Has AI Suggestions: {has_ai_suggestions} (count: {len(ai_suggestions) if isinstance(ai_suggestions, list) else 0})")
                st.write(f"üü¢ **Display Condition Met: {display_condition}**")
                
                if not display_condition:
                    st.error("üö® **This is why you don't see AI results!** None of the AI data keys exist or are populated.")
                    
                    # Show what user needs to do
                    st.markdown("**To see AI analysis:**")
                    st.markdown("1. üîë Configure an API key (Go to AI Config page)")
                    st.markdown("2. üéÜ Select an AI analysis mode (not 'Standard Only')")
                    st.markdown("3. üîÑ Re-run your analysis with AI enabled")
                
                # Show configuration status
                try:
                    from ai_agent import AgentConfig
                    config = AgentConfig.load_config()
                    api_key = AgentConfig.get_api_key()
                    st.write(f"üîê API Key Configured: {'Yes' if api_key else 'No'}")
                    st.write(f"üéØ Current Model: `{config.get('model', 'Not set')}`")
                    st.write(f"üìÖ Config Setup Date: `{config.get('setup_date', 'Not set')}`")
                    
                    if not api_key:
                        st.error("üö® **PROBLEM: No API key configured!** Go to AI Config page to set up your API key.")
                        
                except Exception as e:
                    st.write(f"‚ùå Config Loading Error: {str(e)}")
                
                # Show analysis mode from session state
                ai_mode = getattr(st.session_state, 'last_ai_mode', 'Unknown')
                st.write(f"üéØ Analysis Mode Used: `{ai_mode}`")
                
                if ai_mode == 'üìä Standard Only':
                    st.warning("‚ö†Ô∏è **PROBLEM: You used 'Standard Only' mode!** This skips AI analysis. Use an AI mode like 'Deep Flag Hunt' instead.")
                
                # Show detailed findings data if available
                if isinstance(ai_findings, list) and ai_findings:
                    st.write(f"üîç Sample AI Finding Keys: {list(ai_findings[0].keys()) if ai_findings[0] and isinstance(ai_findings[0], dict) else 'N/A'}")
                    st.markdown("**Sample AI Finding:**")
                    st.json(ai_findings[0] if ai_findings else {})
            
            # Main AI content display with improved logic
            if results.get('ai_status') or results.get('ai_findings') or results.get('ai_suggestions'):
                # ENHANCED: Show AI findings prominently in the AI tab
                if results.get('ai_findings'):
                    st.markdown("### ü§ñ AI Findings (JSON Format) - Main Display")
                    st.markdown("‚ÑπÔ∏è **This is the JSON format display you were looking for!**")
                    
                    ai_findings = results['ai_findings']
                    if isinstance(ai_findings, list) and ai_findings:
                        # Sort by confidence (important results on top as requested)
                        sorted_ai_findings = sorted(ai_findings, key=lambda x: x.get('confidence', 0), reverse=True)
                        
                        st.success(f"üéÜ Found {len(sorted_ai_findings)} AI Discoveries (sorted by confidence, important results first)")
                        
                        for i, ai_finding in enumerate(sorted_ai_findings, 1):
                            if isinstance(ai_finding, dict):
                                confidence = ai_finding.get('confidence', 0)
                                flag_candidate = ai_finding.get('flag_candidate', ai_finding.get('data', 'No data'))
                                
                                # Priority classification
                                if confidence >= 90:
                                    priority = "üèÜ VERY HIGH PRIORITY"
                                    expanded = True
                                elif confidence >= 80:
                                    priority = "‚≠ê HIGH PRIORITY"
                                    expanded = True  
                                elif confidence >= 70:
                                    priority = "üìã MEDIUM PRIORITY"
                                    expanded = i <= 3
                                else:
                                    priority = "‚ö†Ô∏è LOW PRIORITY"
                                    expanded = False
                                
                                with st.expander(f"{priority} - AI Finding #{i} ({confidence}% confidence)", expanded=expanded):
                                    # Display finding data prominently
                                    st.markdown("**üéØ Finding Data:**")
                                    st.code(flag_candidate, language="text")
                                    
                                    # Display full JSON structure as requested
                                    st.markdown("**üìä Complete JSON Structure:**")
                                    st.json(ai_finding)
                                    
                                    # Additional analysis if available
                                    if ai_finding.get('reasoning'):
                                        st.markdown("**üß† AI Reasoning:**")
                                        st.info(ai_finding['reasoning'])
                                    
                                    if ai_finding.get('poc'):
                                        st.markdown("**üîß Proof of Concept:**")
                                        st.code(ai_finding['poc'], language="text")
                            else:
                                with st.expander(f"üîç AI Finding #{i}", expanded=i <= 3):
                                    st.code(str(ai_finding), language="text")
                    
                    elif isinstance(ai_findings, dict):
                        st.markdown("**AI Analysis Structure:**")
                        st.json(ai_findings)
                    
                    else:
                        st.info("AI findings available but in unexpected format.")
                        st.code(str(ai_findings), language="text")
                        
                    st.markdown("---")
                
                # Display Comprehensive AI Analysis Results (Enhanced Analysis mode)
                if results.get('comprehensive_ai_analysis'):
                    st.markdown("### üß† Comprehensive AI Analysis (Enhanced Mode)")
                    st.markdown("‚ÑπÔ∏è **This is the enhanced AI analysis with comprehensive JSON structure!**")
                    
                    comprehensive = results['comprehensive_ai_analysis']
                    
                    # Show analysis overview with metrics
                    if comprehensive.get('analysis_metadata'):
                        metadata = comprehensive['analysis_metadata']
                        col1, col2, col3, col4 = st.columns(4)
                        
                        with col1:
                            st.metric("üìä Success Rate", f"{metadata.get('success_rate_percentage', 0)}%")
                        with col2:
                            st.metric("üîß Components", f"{metadata.get('successful_components', 0)}/{metadata.get('total_components_executed', 0)}")
                        with col3:
                            st.metric("üìù Findings", len(comprehensive.get('validated_findings', [])))
                        with col4:
                            st.metric("üéØ Confidence", f"{comprehensive.get('overall_confidence', 0)}%")
                        
                        st.markdown("---")
                    
                    # Show comprehensive analysis metadata in JSON format
                    with st.expander("üìä Comprehensive Analysis Metadata (JSON)", expanded=True):
                        st.markdown("**üîç Analysis Overview:**")
                        if comprehensive.get('analysis_metadata'):
                            st.json(comprehensive['analysis_metadata'])
                        
                        if comprehensive.get('component_summary'):
                            st.markdown("**üì¶ Component Summary:**")
                            st.json(comprehensive['component_summary'])
                        
                        if comprehensive.get('quality_metrics'):
                            st.markdown("**üèÖ Quality Metrics:**")
                            st.json(comprehensive['quality_metrics'])
                    
                    # Show specialist analysis with enhanced JSON
                    if comprehensive.get('specialist_analysis'):
                        st.markdown("**üî¨ Multi-Agent Specialist Analysis (JSON Format):**")
                        specialist_count = len(comprehensive['specialist_analysis'])
                        st.success(f"ü§ñ {specialist_count} AI specialists analyzed your data")
                        
                        for i, (specialist_name, specialist_result) in enumerate(comprehensive['specialist_analysis'].items(), 1):
                            specialist_confidence = specialist_result.get('confidence', 0) if isinstance(specialist_result, dict) else 0
                            
                            with st.expander(f"ü§ñ {specialist_name} - {specialist_confidence}% Confidence (JSON)", expanded=i <= 2):
                                st.markdown("**üìã Complete Specialist Analysis (JSON):**")
                                st.json(specialist_result)
                                
                                if isinstance(specialist_result, dict):
                                    if specialist_result.get('findings'):
                                        st.markdown("**üéØ Key Findings:**")
                                        for finding in specialist_result['findings'][:3]:
                                            st.code(finding, language="text")
                                    
                                    if specialist_result.get('insights'):
                                        st.markdown("**üß† Specialist Insights:**")
                                        st.info(specialist_result['insights'])
                    
                    # Show validated findings with detailed JSON
                    if comprehensive.get('validated_findings'):
                        st.markdown("**‚úÖ Validated Findings (Comprehensive JSON Format):**")
                        validated = comprehensive['validated_findings']
                        
                        # Show summary stats
                        high_conf = len([f for f in validated if f.get('confidence', 0) >= 85])
                        medium_conf = len([f for f in validated if 70 <= f.get('confidence', 0) < 85])
                        low_conf = len([f for f in validated if f.get('confidence', 0) < 70])
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("üèÜ High Confidence", high_conf)
                        with col2:
                            st.metric("‚≠ê Medium Confidence", medium_conf)
                        with col3:
                            st.metric("üîç Low Confidence", low_conf)
                        
                        for i, finding in enumerate(validated[:10], 1):
                            if isinstance(finding, dict):
                                confidence = finding.get('confidence', 0)
                                data = finding.get('data', 'No data')
                                
                                # Priority classification with icons
                                if confidence >= 90:
                                    priority_icon = "üèÜ"
                                    priority_text = "CRITICAL PRIORITY"
                                    expanded = True
                                elif confidence >= 80:
                                    priority_icon = "‚≠ê"
                                    priority_text = "HIGH PRIORITY"
                                    expanded = i <= 3
                                elif confidence >= 70:
                                    priority_icon = "üìù"
                                    priority_text = "MEDIUM PRIORITY"
                                    expanded = i <= 2
                                else:
                                    priority_icon = "üîç"
                                    priority_text = "LOW PRIORITY"
                                    expanded = False
                                
                                with st.expander(f"{priority_icon} {priority_text} - Validated Finding #{i} ({confidence}% confidence)", expanded=expanded):
                                    st.markdown("**üéØ Finding Data:**")
                                    st.code(data, language="text")
                                    
                                    st.markdown("**üìã Complete Validated Finding (JSON):**")
                                    st.json(finding)
                                    
                                    if finding.get('ai_analysis', {}).get('explanation'):
                                        st.markdown("**üß† AI Analysis:**")
                                        st.info(finding['ai_analysis']['explanation'])
                    
                    # Show flag reconstruction results with enhanced JSON
                    if comprehensive.get('flag_reconstruction', {}).get('reconstructed_flags'):
                        st.markdown("**üèóÔ∏è Flag Reconstruction Results (Comprehensive JSON):**")
                        flag_reconstruction = comprehensive['flag_reconstruction']
                        flags = flag_reconstruction['reconstructed_flags']
                        
                        # Show reconstruction metadata
                        with st.expander("üõ†Ô∏è Flag Reconstruction Analysis (JSON)", expanded=False):
                            st.json(flag_reconstruction)
                        
                        for i, flag in enumerate(flags, 1):
                            confidence = flag.get('confidence', 0)
                            flag_data = flag.get('flag', 'No flag data')
                            method = flag.get('reconstruction_method', 'Unknown method')
                            
                            with st.expander(f"üèóÔ∏è Reconstructed Flag #{i} - {confidence}% Confidence (JSON)", expanded=True):
                                st.markdown("**üéØ Flag Value:**")
                                st.code(flag_data, language="text")
                                
                                st.markdown("**üìã Complete Flag Reconstruction (JSON):**")
                                st.json(flag)
                                
                                st.markdown(f"**üîß Reconstruction Method:** {method}")
                                
                                if flag.get('reconstruction_steps'):
                                    st.markdown("**üìã Reconstruction Steps:**")
                                    for step in flag['reconstruction_steps']:
                                        st.write(f"‚Ä¢ {step}")
                    
                    # Show progressive hints with JSON structure
                    if comprehensive.get('progressive_hints'):
                        st.markdown("**üí° Progressive Hints System (JSON Format):**")
                        hints = comprehensive['progressive_hints']
                        
                        with st.expander(f"üí° {len(hints)} Progressive Hints Available (JSON)", expanded=False):
                            st.json(hints)
                    
                    # Show behavioral patterns with enhanced JSON
                    if comprehensive.get('behavioral_patterns'):
                        st.markdown("**üîç Behavioral Pattern Analysis (JSON Format):**")
                        
                        with st.expander("üîç Behavioral Patterns (JSON)", expanded=False):
                            st.json(comprehensive['behavioral_patterns'])
                    
                    # Show attack narrative with JSON structure
                    if comprehensive.get('attack_narrative'):
                        st.markdown("**üìú AI-Generated Attack Narrative (JSON Format):**")
                        
                        with st.expander("üìú Attack Narrative (JSON)", expanded=False):
                            st.json(comprehensive['attack_narrative'])
                    
                    # Show predictive analysis with JSON
                    if comprehensive.get('predictive_analysis'):
                        st.markdown("**üîÆ Predictive Analysis (JSON Format):**")
                        
                        with st.expander("üîÆ Predictive Analysis (JSON)", expanded=False):
                            st.json(comprehensive['predictive_analysis'])
                    
                    # Show complete comprehensive analysis structure with search
                    with st.expander("üîç Complete Comprehensive Analysis (Full JSON Structure)", expanded=False):
                        st.markdown("**üìã This is the complete JSON structure as requested:**")
                        st.json(comprehensive)
                        
                        # Add JSON download capability
                        import json
                        json_str = json.dumps(comprehensive, indent=2, ensure_ascii=False)
                        st.download_button(
                            label="üíæ Download Complete Analysis JSON",
                            data=json_str,
                            file_name=f"flagsniff_comprehensive_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                            mime="application/json"
                        )
                    
                    st.markdown("---")
                
                if results.get('ai_status'):
                    ai_status = results['ai_status']
                    status_map = {
                        'success': (st.success, "‚úÖ AI Analysis: Completed Successfully"),
                        'comprehensive_success': (st.success, "‚úÖ Comprehensive AI Analysis: Completed Successfully with Enhanced Results"),
                        'comprehensive_no_results': (st.info, "‚ÑπÔ∏è Comprehensive AI Analysis: Completed - No significant findings detected"),
                        'no_results': (st.info, "‚ÑπÔ∏è AI Analysis: No qualifying findings detected"),
                        'disabled': (st.info, "üö´ AI Analysis: Disabled - No API key configured"),
                        'standard_only': (st.info, "üìä AI Analysis: Standard Mode - AI analysis skipped"),
                        'rate_limited': (st.warning, "‚ö†Ô∏è AI Analysis: Rate Limited - Offline analysis completed"),
                        'fallback_success': (st.success, f"‚úÖ AI Analysis: Fallback Success - Used {results.get('ai_fallback_model','fallback model')}"),
                        'fallback_failed': (st.warning, "‚ö†Ô∏è AI Analysis: Fallback Failed - Offline analysis completed"),
                        'all_models_rate_limited': (st.warning, "‚ö†Ô∏è AI Analysis: All Models Rate Limited - Offline analysis completed"),
                        'model_not_found': (st.warning, "‚ö†Ô∏è AI Analysis: Model Not Available - Trying Alternative"),
                        'error': (st.error, "‚ùå AI Analysis: Error Occurred"),
                        'failed': (st.error, "‚ùå AI Analysis: Failed"),
                        'agent_failed': (st.error, "‚ùå AI Analysis: Agent Creation Failed"),
                    }
                    fn, msg = status_map.get(ai_status, (st.info, f"AI status: {ai_status}"))
                    fn(msg)
                    if results.get('ai_error'):
                        st.info(f"Details: {results['ai_error']}")
                if results.get('ai_findings'):
                    st.markdown("**AI Discoveries**")
                    ai_obj = results.get('ai_findings')
                    ai_list = []
                    if isinstance(ai_obj, list):
                        ai_list = ai_obj
                    elif isinstance(ai_obj, dict):
                        for key in ['flag_candidates', 'ai_findings', 'findings', 'enhanced_findings']:
                            val = ai_obj.get(key)
                            if isinstance(val, list):
                                ai_list = val
                                break
                        if not ai_list:
                            ai_list = [ai_obj]
                    for i, finding in enumerate(ai_list[:5]):
                        confidence = finding.get('confidence', 50) if isinstance(finding, dict) else 50
                        with st.expander(f"üö© AI Discovery #{i+1} - {confidence}% Confidence", expanded=True):
                            if isinstance(finding, dict):
                                content_val = finding.get('flag_candidate') or finding.get('flag') or finding.get('data') or finding.get('result') or ''
                                st.code(str(content_val), language="text")
                                if finding.get('reasoning'):
                                    st.markdown("**üß† Reasoning:**")
                                    st.markdown(str(finding['reasoning']))
                                if finding.get('poc'):
                                    st.markdown("**üîß PoC:**")
                                    st.markdown(str(finding['poc']))
                            else:
                                st.code(str(finding), language="text")
                if results.get('ai_suggestions'):
                    st.markdown("**üí° Analysis Recommendations**")
                    
                    suggestions = results['ai_suggestions']
                    
                    # Check if this is fallback analysis
                    is_fallback = any("Analysis Status" in str(s) or "Offline Analysis" in str(s) for s in suggestions[:2])
                    
                    if is_fallback:
                        # Display fallback status prominently
                        status_msg = next((s for s in suggestions if "Analysis Status" in str(s)), "")
                        if status_msg:
                            status_text = str(status_msg).replace("üîÑ **Analysis Status**: ", "")
                            st.info(f"üîÑ **Status**: {status_text}")
                        
                        offline_msg = next((s for s in suggestions if "Offline Analysis" in str(s)), "")
                        if offline_msg:
                            offline_text = str(offline_msg).replace("üìä **Offline Analysis Available**: ", "")
                            st.success(f"üìä **Available**: {offline_text}")
                    
                    # Display actionable suggestions (skip status messages)
                    actionable_suggestions = [s for s in suggestions if not any(skip in str(s) for skip in ["Analysis Status", "Offline Analysis Available"])]
                    
                    if actionable_suggestions:
                        st.markdown("**üéØ Recommended Actions:**")
                        for i, suggestion in enumerate(actionable_suggestions[:8], 1):
                            # Format suggestion for better readability
                            suggestion_text = str(suggestion)
                            if suggestion_text.startswith("üí° **Note**"):
                                st.info(suggestion_text.replace("üí° **Note**: ", ""))
                            else:
                                st.write(f"{i}. {suggestion_text}")
                # Also display any specialized analyses if present
                for key, title in [
                    ('protocol_analysis', 'Protocol Analysis'),
                    ('credential_analysis', 'Credential Analysis'),
                    ('behavioral_analysis', 'Behavioral Analysis'),
                    ('ai_analysis', 'Enhanced Analysis'),
                    ('enhanced_flag_hunt', 'Enhanced Flag Hunt')
                ]:
                    if results.get(key):
                        with st.expander(f"{title}"):
                            val = results.get(key)
                            if isinstance(val, (dict, list)):
                                st.json(val)
                            else:
                                st.write(str(val))
            else:
                # Always show helpful information when AI data is not available
                st.info("ü§ñ **AI Analysis Setup Guide**")
                
                st.markdown("""
                **To enable AI-powered analysis:**
                1. üîë Get a free API key from [OpenRouter](https://openrouter.ai/)
                2. ‚öôÔ∏è Go to the **AI Config** page to set up your key
                3. üéØ Choose from multiple free AI models
                4. üöÄ Re-run your analysis with AI mode enabled
                
                **Available without AI:**
                - üîç Pattern matching and regex searches
                - üìÅ File carving and extraction
                - üîç Protocol analysis and packet inspection
                - üóìÔ∏è Timeline and correlation analysis
                """)
                
                # Show basic analysis suggestions based on findings
                findings_count = len(results.get('findings', []))
                if findings_count > 0:
                    st.success(f"üéâ Found {findings_count} findings using standard analysis!")
                    
                    # Provide basic recommendations based on findings types
                    findings = results.get('findings', [])
                    if findings:
                        finding_types = set(f.get('display_type', 'Unknown') for f in findings)
                        
                        st.markdown("**üí° Manual Analysis Suggestions:**")
                        
                        if any('FLAG' in ft.upper() for ft in finding_types):
                            st.write("‚Ä¢ üèÜ **Flags detected** - Review flag candidates in the Findings tab")
                            
                        if any('CREDENTIAL' in ft.upper() for ft in finding_types):
                            st.write("‚Ä¢ üîê **Credentials found** - Check for authentication data")
                            
                        if any('TOKEN' in ft.upper() for ft in finding_types):
                            st.write("‚Ä¢ üé´ **Tokens discovered** - Analyze API tokens and sessions")
                            
                        if any('HTTP' in ft.upper() for ft in finding_types):
                            st.write("‚Ä¢ üåê **HTTP traffic** - Review web requests and responses")
                            
                        if any('FILE' in ft.upper() for ft in finding_types):
                            st.write("‚Ä¢ üìÅ **Files extracted** - Check the Files tab for carved content")
                else:
                    st.info("üóìÔ∏è No automatic findings detected. Try:")
                    st.write("‚Ä¢ üéØ Custom regex patterns for specific targets")
                    st.write("‚Ä¢ üîç Manual packet inspection in the Packets tab")
                    st.write("‚Ä¢ üìÅ File carving results in the Files tab")
                    st.write("‚Ä¢ üï∞Ô∏è Timeline analysis for suspicious patterns")

        # Visuals Tab
        with tabs[5]:
            st.markdown("### üìà Visualizations")
            vis = st.session_state.ctf_visualizer if 'ctf_visualizer' in st.session_state else None
            if results.get('findings') and vis:
                try:
                    st.markdown("#### Findings Distribution")
                    fig = st.session_state.ctf_visualizer.create_findings_distribution(results['findings'])
                    st.plotly_chart(fig, use_container_width=True)
                except Exception:
                    pass
                try:
                    st.markdown("#### Confidence Heatmap")
                    fig2 = st.session_state.ctf_visualizer.create_confidence_heatmap(results['findings'])
                    st.plotly_chart(fig2, use_container_width=True)
                except Exception:
                    pass
            else:
                st.info("üìà **Visualization Data Status**")
                
                # Check what data is available
                total_findings = len(results.get('findings', [])) + len(results.get('ai_findings', []))
                timeline_events = len(results.get('timeline', []))
                protocol_count = len(results.get('statistics', {}).get('protocols', {}))
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Total Findings", total_findings)
                with col2:
                    st.metric("Timeline Events", timeline_events)
                with col3:
                    st.metric("Protocols Detected", protocol_count)
                
                if total_findings == 0 and timeline_events == 0 and protocol_count == 0:
                    st.warning("üîç **No analysis data available yet.** Please run analysis on a PCAP file to populate findings and visualizations.")
                    st.info("**Next steps:**")
                    st.write("1. Upload a PCAP file using the file uploader above")
                    st.write("2. Click 'Analyze PCAP' to process the file")
                    st.write("3. Review results in this tab and others")
                else:
                    st.success("‚úì **Analysis data is available!** Use the buttons above to generate visualizations, or check other tabs for detailed results.")
                    
                    if total_findings > 0:
                        st.write(f"‚Ä¢ **Findings Tab**: View {total_findings} discovered findings")
                    if timeline_events > 0:
                        st.write(f"‚Ä¢ **Timeline Tab**: Browse {timeline_events} chronological events")
                    if protocol_count > 0:
                        st.write(f"‚Ä¢ **Protocols Tab**: Analyze {protocol_count} different protocols")

        # Timeline Tab
        with tabs[6]:
            st.markdown("### üïí Timeline")
            timeline = results.get('timeline') or []
            if not timeline:
                st.info("No timeline events available.")
            else:
                max_rows = st.slider("Max events to display", 50, 2000, min(500, len(timeline)), key="timeline_max")
                cols = ["datetime","type","protocol","src_ip","dst_ip","description"]
                rows = []
                for e in timeline[:max_rows]:
                    rows.append({k: e.get(k,'') for k in cols})
                try:
                    import pandas as _pd
                    st.dataframe(_pd.DataFrame(rows))
                except Exception:
                    for r in rows:
                        st.write(" - ", r.get('datetime',''), r.get('type',''), r.get('protocol',''), f"{r.get('src_ip','')} ‚Üí {r.get('dst_ip','')}", r.get('description',''))
            # Correlation Graph (simple Plotly scatter for nodes and lines for edges)
            graph = results.get('correlation_graph') or {}
            nodes = graph.get('nodes') or []
            edges = graph.get('edges') or []
            if nodes and edges:
                st.markdown("#### Correlation Graph")
                try:
                    import plotly.graph_objects as go
                    # Assign simple positions in a circle
                    import math
                    n = len(nodes)
                    positions = {}
                    for i, node in enumerate(nodes):
                        angle = 2 * math.pi * i / max(n,1)
                        positions[node['id']] = (math.cos(angle), math.sin(angle))
                    edge_x = []
                    edge_y = []
                    for e in edges:
                        s = positions.get(e.get('source'))
                        t = positions.get(e.get('target'))
                        if s and t:
                            edge_x += [s[0], t[0], None]
                            edge_y += [s[1], t[1], None]
                    node_x = [positions[n['id']][0] for n in nodes if n['id'] in positions]
                    node_y = [positions[n['id']][1] for n in nodes if n['id'] in positions]
                    node_text = [f"{n.get('type','node')}: {n.get('id')}" for n in nodes if n['id'] in positions]
                    edge_trace = go.Scatter(x=edge_x, y=edge_y, line=dict(width=1, color='#888'), hoverinfo='none', mode='lines')
                    node_trace = go.Scatter(x=node_x, y=node_y, mode='markers', hoverinfo='text', text=node_text,
                                            marker=dict(showscale=False, color='#00bcd4', size=10, line_width=2))
                    fig = go.Figure(data=[edge_trace, node_trace], layout=go.Layout(showlegend=False,
                                margin=dict(l=0,r=0,b=0,t=0), xaxis=dict(visible=False), yaxis=dict(visible=False)))
                    st.plotly_chart(fig, use_container_width=True)
                except Exception:
                    st.info("Correlation graph available, but Plotly rendering failed.")

        # Files Tab
        with tabs[7]:
            st.markdown("### üóÇÔ∏è Extracted Files / File Carving Results")
            files_list = results.get('file_carving_results', []) or results.get('extracted_files', [])
            if not files_list:
                st.info("No carved or extracted files found.")
            else:
                # Filters
                name_filter = st.text_input("Search by name/hash", key="file_name_filter")
                min_size = st.slider("Minimum size (bytes)", 0, 1000000, 0, key="file_min_size")
                uniq = st.checkbox("Unique by hash", value=True, key="file_unique_hash")
                show_stego = st.checkbox("Show files with steganography hints", value=False, key="file_stego_filter")
                
                # Sub-tabs by category
                cat_tabs = st.tabs(["All", "Images", "Docs", "Archives", "Binaries", "Audio/Video", "CTF Files", "Other"])
                categories = {
                    'Images': {"png","jpg","gif","ico","webp","bmp"},
                    'Docs': {"pdf","doc","docx","rtf","txt"},
                    'Archives': {"zip","gz","bz2","7z","rar"},
                    'Binaries': {"exe","elf","dll","so"},
                    'Audio/Video': {"mp3","wav","mp4","avi","flv","mkv"},
                    'CTF Files': {"txt"},  # Special handling for CTF files
                }
                
                def apply_filters(items, allowed_exts=None):
                    filtered = []
                    seen = set()
                    for idx, fobj in enumerate(items):
                        name = fobj.get('name') or fobj.get('filename') or f"carved_file_{idx}"
                        ext = (fobj.get('ext') or fobj.get('extension') or '').lower()
                        fhash = fobj.get('hash') or fobj.get('sha256') or fobj.get('md5_hash', '')
                        size = fobj.get('size', len(fobj.get('data', b'')) if isinstance(fobj.get('data'), (bytes, bytearray)) else 0)
                        
                        # Special handling for CTF files (check if it's a flag file)
                        is_ctf_file = False
                        if 'CTF' in fobj.get('file_type', '') or any(flag_indicator in fobj.get('file_type', '') for flag_indicator in ['Flag', 'CTF']):
                            is_ctf_file = True
                        
                        # Apply name filter
                        if name_filter and name_filter.lower() not in (name.lower() + fhash.lower()):
                            continue
                            
                        # Apply size filter
                        if size < min_size:
                            continue
                            
                        # Apply extension filter
                        if allowed_exts is not None:
                            if 'CTF Files' in allowed_exts and is_ctf_file:
                                pass  # Allow CTF files
                            elif ext not in allowed_exts:
                                continue
                        
                        # Apply steganography filter
                        if show_stego:
                            analysis = fobj.get('analysis', {})
                            if not analysis.get('stego') and not analysis.get('metadata', {}).get('exif'):
                                continue
                        
                        key = fhash if uniq else (name, size)
                        if uniq and fhash and key in seen:
                            continue
                        seen.add(key)
                        
                        # uid is a stable per-file identifier for widget keys
                        uid = fhash or f"{name}_{size}_{idx}"
                        filtered.append((idx, fobj, name, ext, fhash, size, uid, is_ctf_file))
                    return filtered
                
                def render_list(filtered, key_prefix:"str"="all"):
                    if not filtered:
                        st.info("No files match the current filters.")
                        return
                    
                    for idx, fobj, name, ext, fhash, size, uid, is_ctf_file in filtered:
                        # Enhanced file display with preview
                        with st.container():
                            # File header with metadata
                            col1, col2, col3 = st.columns([3, 1, 1])
                            
                            with col1:
                                # Show actual filename if available
                                actual_name = fobj.get('actual_name') or fobj.get('original_name') or name
                                if actual_name != name:
                                    st.markdown(f"**üìÑ {actual_name}** *(carved as: {name})*")
                                else:
                                    st.markdown(f"**üìÑ {name}{('.' + ext) if ext else ''}**")
                                
                                # Special indicator for CTF files
                                if is_ctf_file:
                                    st.markdown("üèÜ **CTF FLAG FILE**")
                                
                                # File metadata
                                metadata_info = []
                                metadata_info.append(f"Size: {size:,} bytes")
                                if fhash:
                                    metadata_info.append(f"Hash: {fhash[:16]}..." if len(fhash) > 16 else f"Hash: {fhash}")
                                if fobj.get('source_protocol'):
                                    metadata_info.append(f"Protocol: {fobj.get('source_protocol')}")
                                if fobj.get('stream_id'):
                                    metadata_info.append(f"Stream: {fobj.get('stream_id')}")
                                if fobj.get('carving_method'):
                                    metadata_info.append(f"Method: {fobj.get('carving_method')}")
                                
                                st.caption(" | ".join(metadata_info))
                            
                            with col2:
                                file_type = fobj.get('file_type', 'Unknown')
                                st.markdown(f"**Type:** {file_type}")
                            
                            with col3:
                                # Download button
                                raw = fobj.get('data')
                                data_bytes = None
                                if isinstance(raw, (bytes, bytearray)):
                                    data_bytes = raw
                                elif isinstance(raw, str):
                                    try:
                                        import base64
                                        data_bytes = base64.b64decode(raw)
                                    except Exception:
                                        data_bytes = None
                                
                                if data_bytes:
                                    download_name = actual_name if actual_name != name else f"{name}{('.' + ext) if ext else ''}"
                                    st.download_button(
                                        label="‚¨áÔ∏è Download",
                                        data=data_bytes,
                                        file_name=download_name,
                                        mime="application/octet-stream",
                                        key=f"dl_{key_prefix}_{uid}",
                                        use_container_width=True
                                    )
                            
                            # Enhanced File Preview Section
                            if data_bytes and len(data_bytes) > 0:
                                st.markdown("---")
                                
                                # Check for steganography analysis
                                analysis = fobj.get('analysis', {})
                                stego_findings = analysis.get('stego', [])
                                metadata = analysis.get('metadata', {})
                                strings = analysis.get('strings', [])
                                
                                # Show steganography findings
                                if stego_findings:
                                    st.markdown("### üïµÔ∏è Steganography Analysis")
                                    for i, stego in enumerate(stego_findings):
                                        st.markdown(f"**{stego.get('method', 'Hidden Data')}**")
                                        content = stego.get('content', '')
                                        if len(content) > 200:
                                            st.text_area(f"Content (truncated)", value=content[:200] + "...", key=f"stego_content_{uid}_{i}", height=100)
                                        else:
                                            st.text_area(f"Content", value=content, key=f"stego_content_{uid}_{i}", height=100)
                                        
                                        # Add download button for extracted content
                                        st.download_button(
                                            label="‚¨áÔ∏è Export extracted content",
                                            data=str(content).encode('utf-8', errors='ignore'),
                                            file_name=f"{actual_name}_extracted_{stego.get('type','content')}.txt",
                                            mime="text/plain",
                                            key=f"dl_stego_{key_prefix}_{uid}_{i}"
                                        )
                                
                                # Show metadata
                                if metadata:
                                    st.markdown("### üìä File Metadata")
                                    # Show EXIF data for images
                                    exif = metadata.get('exif')
                                    if exif:
                                        st.markdown("**üì∑ EXIF Data:**")
                                        st.json(exif)
                                    
                                    # Show ZIP file contents
                                    zip_files = metadata.get('zip_files')
                                    if zip_files:
                                        st.markdown("**üì¶ ZIP Contents:**")
                                        st.json(zip_files[:10])  # Show first 10 files
                                        if len(zip_files) > 10:
                                            st.caption(f"... and {len(zip_files) - 10} more files")
                                    
                                    # Show interesting files in archives
                                    interesting_files = metadata.get('interesting_files')
                                    if interesting_files:
                                        st.markdown("**üîç Interesting Files in Archive:**")
                                        for filename in interesting_files:
                                            st.code(filename, language="text")
                                
                                # Show extracted strings
                                if strings:
                                    with st.expander("üî§ Extracted Strings"):
                                        for i, s in enumerate(strings[:10]):  # Show first 10 strings
                                            st.code(s, language="text")
                                        if len(strings) > 10:
                                            st.caption(f"... and {len(strings) - 10} more strings")
                                
                                st.markdown("---")
                                
                                # File preview based on type
                                st.markdown("### üîç File Preview")
                                
                                preview_container = st.container()
                                
                                with preview_container:
                                    # Enhanced Image Preview with Enhanced Features
                                    if ext.lower() in ['png', 'jpg', 'jpeg', 'gif', 'bmp', 'ico', 'webp', 'tiff', 'svg']:
                                        try:
                                            st.markdown("**üñºÔ∏è Image Preview:**")
                                            
                                            # Show image with size limits
                                            if size < 10 * 1024 * 1024:  # 10MB limit
                                                col_img1, col_img2 = st.columns([2, 1])
                                                
                                                with col_img1:
                                                    # Enhanced BytesIO handling for images
                                                    try:
                                                        import io
                                                        from PIL import Image
                                                        
                                                        if isinstance(data_bytes, (bytes, bytearray)):
                                                            # Try to validate image data first
                                                            try:
                                                                # Create BytesIO object and validate
                                                                img_io = io.BytesIO(data_bytes)
                                                                img = Image.open(img_io)
                                                                img.verify()  # Verify the image
                                                                
                                                                # Reset BytesIO for display
                                                                img_io.seek(0)
                                                                st.image(img_io, 
                                                                        caption=f"{actual_name} ({size:,} bytes)", 
                                                                        use_container_width=True)
                                                            except (Image.UnidentifiedImageError, OSError) as e:
                                                                if "cannot identify image file" in str(e) or "truncated" in str(e).lower():
                                                                    st.warning(f"‚ö†Ô∏è Image appears corrupted or truncated: {actual_name}")
                                                                    st.info("üí° This may be intentional for steganography or the file may be partially extracted")
                                                                    # Show file signature for debugging
                                                                    if len(data_bytes) >= 16:
                                                                        hex_sig = ' '.join([f'{b:02x}' for b in data_bytes[:16]])
                                                                        st.code(f"File signature: {hex_sig}", language='text')
                                                                else:
                                                                    st.error(f"Cannot display image: {str(e)}")
                                                        else:
                                                            st.error("Invalid image data format")
                                                    except Exception as img_error:
                                                        st.error(f"Cannot display image: {str(img_error)}")
                                                        # Show hex preview as fallback
                                                        try:
                                                            hex_preview = data_bytes[:64].hex()
                                                            formatted_hex = ' '.join([hex_preview[i:i+2] for i in range(0, len(hex_preview), 2)])
                                                            st.code(formatted_hex, language='text')
                                                            st.caption("Image data (hex preview)")
                                                        except Exception:
                                                            pass
                                                
                                                with col_img2:
                                                    # Enhanced Image metadata
                                                    try:
                                                        from PIL import Image
                                                        from PIL.ExifTags import TAGS
                                                        import io
                                                        
                                                        if isinstance(data_bytes, (bytes, bytearray)):
                                                            img = Image.open(io.BytesIO(data_bytes))
                                                            st.markdown(f"**üìê Dimensions:** {img.size[0]} √ó {img.size[1]} pixels")
                                                            st.markdown(f"**üé® Mode:** {img.mode}")
                                                            st.markdown(f"**üìÅ Format:** {img.format}")
                                                            
                                                            # Calculate megapixels
                                                            megapixels = (img.size[0] * img.size[1]) / 1000000
                                                            st.markdown(f"**üìä Resolution:** {megapixels:.2f} MP")
                                                            
                                                            # EXIF data if available
                                                            try:
                                                                exifdata = img.getexif()
                                                                if exifdata:
                                                                    st.success("**üì∑ EXIF Data Found** ‚úì")
                                                                    with st.expander("üîç View EXIF Data"):
                                                                        exif_dict = {}
                                                                        for tag_id in exifdata:
                                                                            tag = TAGS.get(tag_id, tag_id)
                                                                            data = exifdata.get(tag_id)
                                                                            if isinstance(data, bytes):
                                                                                data = data.decode('utf-8', errors='ignore')
                                                                            exif_dict[tag] = data
                                                                        
                                                                        # Show key EXIF fields
                                                                        key_fields = ['DateTime', 'Make', 'Model', 'Software', 'GPS GPSLatitude', 'GPS GPSLongitude']
                                                                        for field in key_fields:
                                                                            if field in exif_dict:
                                                                                st.markdown(f"**{field}:** {exif_dict[field]}")
                                                                        
                                                                        # Show all EXIF data
                                                                        with st.expander("All EXIF Data"):
                                                                            st.json(exif_dict)
                                                            except Exception:
                                                                pass
                                                    except Exception:
                                                        pass
                                            else:
                                                st.info("üñºÔ∏è Large image file - preview not available")
                                        
                                        except Exception as e:
                                            st.error(f"Error displaying image: {str(e)}")
                                    
                                    # Text file preview
                                    elif ext.lower() in ['txt', 'log', 'md', 'csv', 'json', 'xml', 'html', 'css', 'js', 'py', 'sh']:
                                        try:
                                            st.markdown("**üìù Text Content Preview:**")
                                            # Try to decode as text
                                            text_content = data_bytes.decode('utf-8', errors='ignore')
                                            if len(text_content) > 10000:
                                                st.text_area("Content (first 10KB)", value=text_content[:10000], height=300, key=f"text_preview_{uid}")
                                                st.caption(f"... and {len(text_content) - 10000} more characters")
                                            else:
                                                st.text_area("Content", value=text_content, height=300, key=f"text_preview_{uid}")
                                        except Exception:
                                            st.info("Unable to display text content")
                                    
                                    # PDF preview
                                    elif ext.lower() == 'pdf':
                                        st.markdown("**üìÑ PDF File**")
                                        st.info("PDF preview not available in this interface. Download the file to view.")
                                    
                                    # ZIP preview
                                    elif ext.lower() in ['zip', 'rar', '7z', 'gz', 'bz2']:
                                        st.markdown("**üì¶ Archive File**")
                                        st.info("Archive preview not available in this interface. Download and extract the file to view contents.")
                                    
                                    else:
                                        st.markdown("**üìÑ Binary File**")
                                        st.info("Binary file preview not available. Download the file to analyze.")
                            
                            st.markdown("---")
                
                with cat_tabs[0]:
                    render_list(apply_filters(files_list), key_prefix="all")
                with cat_tabs[1]:
                    render_list(apply_filters(files_list, categories['Images']), key_prefix="images")
                with cat_tabs[2]:
                    render_list(apply_filters(files_list, categories['Docs']), key_prefix="docs")
                with cat_tabs[3]:
                    render_list(apply_filters(files_list, categories['Archives']), key_prefix="archives")
                with cat_tabs[4]:
                    render_list(apply_filters(files_list, categories['Binaries']), key_prefix="binaries")
                with cat_tabs[5]:
                    render_list(apply_filters(files_list, categories['Audio/Video']), key_prefix="av")
                with cat_tabs[6]:
                    render_list(apply_filters(files_list, categories['CTF Files']), key_prefix="ctf")
                with cat_tabs[7]:
                    render_list(apply_filters(files_list, set()), key_prefix="other")

        except Exception as e:
            st.error(f"‚ùå Error reading archive: {str(e)}")
                    st.code(formatted_hex, language='text')
                    st.caption("Hex preview of first 64 bytes")
                except Exception:
                    pass

            # Handle other archive formats (RAR, 7Z, TAR, etc.)
            else:
                st.info(f"üì¶ **{ext.upper()} Archive Detected**")
                st.markdown(f"**üìÅ Filename:** {actual_name}")
                st.markdown(f"**üìè Size:** {size:,} bytes ({size/(1024*1024):.2f} MB)")

                # Show basic information for non-ZIP archives
                if ext.lower() == 'rar':
                    st.info("üì¶ RAR archive detected. Use WinRAR or 7-Zip to extract.")
                elif ext.lower() == '7z':
                    st.info("üì¶ 7-Zip archive detected. Use 7-Zip to extract.")
                elif ext.lower() in ['tar', 'gz', 'bz2', 'xz']:
                    st.info(f"üì¶ TAR/{ext.upper()} archive detected. Use appropriate tools to extract.")

                # Show basic hex preview for structure analysis
                with st.expander("üîç Archive Header Analysis"):
                    header_bytes = data_bytes[:128]
                    hex_preview = header_bytes.hex()
                    formatted_hex = ' '.join([hex_preview[i:i+2] for i in range(0, len(hex_preview), 2)])
                    st.code(formatted_hex, language='text')
                    st.caption("First 128 bytes of archive header")
        except Exception as e:
            st.error(f"‚ùå Error reading archive: {str(e)}")
                                                        if creator_match:
                                                            st.markdown(f"**üé® Creator:** {creator_match.group(1)}")
                                                            
                                                except Exception:
                                                    pass
                                            
                                            with col_pdf2:
                                                st.markdown("**üîç Security Analysis:**")
                                                
                                                # Check for embedded content
                                                if b'/JavaScript' in data_bytes:
                                                    st.warning("‚ö†Ô∏è JavaScript detected")
                                                if b'/EmbeddedFile' in data_bytes:
                                                    st.warning("üìÅ Embedded files detected")
                                                if b'/Form' in data_bytes:
                                                    st.info("üìã Forms detected")
                                                if b'/Encrypt' in data_bytes:
                                                    st.warning("üîí Encryption detected")
                                                
                                                st.info("üí° **Tip:** Download to view full PDF content")
                                            
                                            # Show hex preview of PDF header
                                            with st.expander("üîç PDF Header Analysis"):
                                                header_bytes = data_bytes[:256]
                                                hex_preview = header_bytes.hex()
                                                formatted_hex = ' '.join([hex_preview[i:i+2] for i in range(0, len(hex_preview), 2)])
                                                st.code(formatted_hex, language='text')
                                                st.caption("First 256 bytes in hexadecimal")
                                                
                                        except Exception as e:
                                            st.error(f"‚ùå Error analyzing PDF: {str(e)}")
                                    
                                    # Enhanced Text File Preview
                                    elif (ext.lower() in ['txt', 'md', 'csv', 'json', 'xml', 'html', 'js', 'css', 'py', 'java', 'c', 'cpp', 'h', 'php', 'sql', 'log'] or 
                                          size < 1024):  # Small files are likely text
                                        try:
                                            st.markdown("**üìù Text File Preview:**")
                                            
                                            # Try to decode as text with multiple encodings
                                            try:
                                                text_content = None
                                                encoding_used = 'utf-8'
                                                encodings = ['utf-8', 'latin1', 'cp1252', 'ascii']
                                                
                                                for encoding in encodings:
                                                    try:
                                                        text_content = data_bytes.decode(encoding)
                                                        encoding_used = encoding
                                                        break
                                                    except UnicodeDecodeError:
                                                        continue
                                                
                                                if text_content and text_content.strip():
                                                    col_text1, col_text2 = st.columns([3, 1])
                                                    
                                                    with col_text1:
                                                        # Show preview with syntax highlighting if possible
                                                        language = {
                                                            'py': 'python', 'js': 'javascript', 'html': 'html',
                                                            'css': 'css', 'json': 'json', 'xml': 'xml',
                                                            'java': 'java', 'c': 'c', 'cpp': 'cpp', 'php': 'php',
                                                            'sql': 'sql', 'md': 'markdown', 'log': 'text'
                                                        }.get(ext.lower(), 'text')
                                                        
                                                        preview_text = text_content[:3000]  # 3KB preview
                                                        if len(text_content) > 3000:
                                                            preview_text += '\n\n... (file truncated for preview)'
                                                        
                                                        st.code(preview_text, language=language)
                                                        st.caption(f"Showing first 3KB of {len(text_content):,} total characters")
                                                    
                                                    with col_text2:
                                                        st.markdown("**üìä Text Analysis:**")
                                                        
                                                        # Text statistics
                                                        lines = text_content.count('\n') + 1
                                                        words = len(text_content.split())
                                                        chars = len(text_content)
                                                        
                                                        st.markdown(f"**üìú Lines:** {lines:,}")
                                                        st.markdown(f"**üìù Words:** {words:,}")
                                                        st.markdown(f"**üî§ Characters:** {chars:,}")
                                                        st.markdown(f"**üî† Encoding:** {encoding_used.upper()}")
                                                        
                                                        # Check for interesting patterns
                                                        if 'flag{' in text_content.lower() or 'ctf{' in text_content.lower():
                                                            st.success("üèÅ **Flag pattern detected!**")
                                                        
                                                        if 'password' in text_content.lower() or 'passwd' in text_content.lower():
                                                            st.warning("üîë **Password references found**")
                                                        
                                                        if 'base64' in text_content.lower() or re.search(r'[A-Za-z0-9+/]{20,}={0,2}', text_content):
                                                            st.info("üîÑ **Base64 encoding detected**")
                                                        
                                                        if re.search(r'[0-9a-fA-F]{32}', text_content):
                                                            st.info("üî¢ **Hash values detected**")
                                                        
                                                        if 'http://' in text_content or 'https://' in text_content:
                                                            st.info("üåê **URLs found**")
                                                        
                                                        if re.search(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', text_content):
                                                            st.info("üìß **Email addresses found**")
                                                else:
                                                    st.info("File appears to be empty or contains only whitespace")
                                            except Exception:
                                                st.warning("File contains binary data and cannot be displayed as text")
                                                # Show hex preview for binary files
                                                hex_preview = data_bytes[:512].hex()
                                                formatted_hex = ' '.join([hex_preview[i:i+2] for i in range(0, len(hex_preview), 2)])
                                                st.code(formatted_hex, language='text')
                                                st.caption("Hex preview (first 512 bytes)")
                                        except Exception as e:
                                            st.error(f"‚ùå Error previewing file: {str(e)}")
                                    
                                    # Enhanced Binary File Analysis
                                    else:
                                        st.markdown("**‚öôÔ∏è Binary File Analysis:**")
                                        
                                        col_bin1, col_bin2 = st.columns([2, 1])
                                        
                                        with col_bin1:
                                            # Show enhanced hex preview for binary files
                                            try:
                                                st.markdown("**üîç Enhanced Hex Dump:**")
                                                
                                                # Format hex dump with addresses and ASCII
                                                hex_lines = []
                                                max_bytes = min(512, len(data_bytes))
                                                for i in range(0, max_bytes, 16):
                                                    chunk = data_bytes[i:i+16]
                                                    hex_part = ' '.join(f"{b:02x}" for b in chunk)
                                                    ascii_part = ''.join(chr(b) if 32 <= b < 127 else '.' for b in chunk)
                                                    hex_lines.append(f"{i:08x}: {hex_part:<47} |{ascii_part}|")
                                                
                                                st.code('\n'.join(hex_lines), language='text')
                                                st.caption("Hex dump with ASCII representation (first 512 bytes)")
                                                
                                            except Exception as e:
                                                st.error(f"Error creating hex preview: {str(e)}")
                                        
                                        with col_bin2:
                                            st.markdown("**üïµÔ∏è File Analysis:**")
                                            
                                            # Enhanced file type detection
                                            magic_signatures = {
                                                b'\x89PNG\r\n\x1a\n': 'üñºÔ∏è PNG Image',
                                                b'\xff\xd8\xff': 'üñºÔ∏è JPEG Image', 
                                                b'GIF87a': 'üñºÔ∏è GIF Image (87a)',
                                                b'GIF89a': 'üñºÔ∏è GIF Image (89a)',
                                                b'%PDF-': 'üìã PDF Document',
                                                b'PK\x03\x04': 'üì¶ ZIP Archive',
                                                b'PK\x05\x06': 'üì¶ ZIP Archive (empty)',
                                                b'PK\x07\x08': 'üì¶ ZIP Archive (spanned)',
                                                b'RIFF': 'üéµ RIFF Container (WAV/AVI)',
                                                b'\x00\x00\x00\x20ftyp': 'üé¨ MP4 Video',
                                                b'ftyp': 'üé¨ MP4/QuickTime',
                                                b'MZ': '‚öôÔ∏è Windows Executable (PE)',
                                                b'\x7fELF': '‚öôÔ∏è Linux Executable (ELF)',
                                                b'\xca\xfe\xba\xbe': '‚öôÔ∏è Java Class File',
                                                b'\xfe\xed\xfa': '‚öôÔ∏è Mach-O Binary',
                                                b'BM': 'üñºÔ∏è BMP Image',
                                                b'\x00\x00\x01\x00': 'üñºÔ∏è ICO Image',
                                                b'\x1f\x8b\x08': 'üóÉÔ∏è GZIP Archive',
                                                b'Rar!': 'üì¶ RAR Archive',
                                                b'7z\xbc\xaf\'\x1c': 'üì¶ 7-Zip Archive'
                                            }
                                            
                                            detected_type = None
                                            for signature, file_type in magic_signatures.items():
                                                if data_bytes.startswith(signature):
                                                    detected_type = file_type
                                                    break
                                            
                                            if detected_type:
                                                st.success(f"**Detected:** {detected_type}")
                                            else:
                                                st.info("**Type:** Unknown binary file")
                                            
                                            # File entropy analysis (indicates compression/encryption)
                                            try:
                                                import collections
                                                sample_size = min(1024, len(data_bytes))
                                                byte_counts = collections.Counter(data_bytes[:sample_size])
                                                entropy = 0
                                                for count in byte_counts.values():
                                                    if count > 0:
                                                        p = count / sample_size
                                                        entropy -= p * (p.bit_length() - 1 if p < 1 else 8)
                                                
                                                st.markdown(f"**üìä Entropy:** {entropy:.2f} / 8.0")
                                                if entropy > 7.5:
                                                    st.warning("üîí High entropy (likely encrypted/compressed)")
                                                elif entropy < 3.0:
                                                    st.info("üìÑ Low entropy (text-like or structured data)")
                                                else:
                                                    st.info("üîÑ Medium entropy (mixed binary data)")
                                            except Exception:
                                                pass
                                            
                                            # Extract and show readable strings
                                            try:
                                                strings_found = []
                                                current_string = ""
                                                for byte in data_bytes[:2048]:  # Check first 2KB
                                                    if 32 <= byte <= 126:  # Printable ASCII
                                                        current_string += chr(byte)
                                                    else:
                                                        if len(current_string) >= 4:
                                                            strings_found.append(current_string)
                                                        current_string = ""
                                                
                                                # Add final string if exists
                                                if len(current_string) >= 4:
                                                    strings_found.append(current_string)
                                                
                                                if strings_found:
                                                    st.markdown(f"**üî§ Strings Found:** {len(strings_found)}")
                                                    
                                                    # Check for interesting patterns in strings
                                                    flag_strings = [s for s in strings_found if 'flag{' in s.lower() or 'ctf{' in s.lower()]
                                                    if flag_strings:
                                                        st.success(f"üèÅ **Flag patterns in strings!** ({len(flag_strings)} found)")
                                                    
                                                    url_strings = [s for s in strings_found if 'http://' in s or 'https://' in s]
                                                    if url_strings:
                                                        st.info(f"üåê **URLs found** ({len(url_strings)})")
                                                    
                                                    with st.expander("üîç View Extracted Strings"):
                                                        for i, s in enumerate(strings_found[:30]):  # Show first 30 strings
                                                            if len(s) > 60:
                                                                display_string = s[:60] + '...'
                                                            else:
                                                                display_string = s
                                                            st.code(display_string, language='text')
                                                        
                                                        if len(strings_found) > 30:
                                                            st.caption(f"... and {len(strings_found) - 30} more strings")
                                                else:
                                                    st.info("No readable strings found")
                                            except Exception:
                                                pass
                            
                            # Carved File Details (analysis & stego notes)
                            analysis = fobj.get('analysis') or {}
                            if analysis:
                                with st.expander(f"üî¨ Detailed Analysis: {actual_name}"):
                                    meta = analysis.get('metadata') or {}
                                    stego = analysis.get('stego') or []
                                    
                                    if meta:
                                        st.markdown("**üìä Metadata Analysis:**")
                                        
                                        # Highlight important EXIF data
                                        exif = meta.get('exif') or {}
                                        if exif:
                                            highlights = {k: exif.get(k) for k in ['GPSInfo','Artist','Software','Make','Model','DateTime'] if exif.get(k)}
                                            if highlights:
                                                st.markdown("**üéØ EXIF Highlights:**")
                                                for key, value in highlights.items():
                                                    st.markdown(f"- **{key}:** {value}")
                                            
                                            with st.expander("Full EXIF Data"):
                                                st.json(exif)
                                        else:
                                            st.json(meta)
                                    
                                    if stego:
                                        st.markdown("**üïµÔ∏è Steganography Indicators:**")
                                        for s in stego:
                                            st.markdown(f"**{s.get('type','Analysis').title()}:**")
                                            content = s.get('content')
                                            if content:
                                                st.code(str(content)[:1000] + ('...' if len(str(content)) > 1000 else ''), language='text')
                                                st.download_button(
                                                    label="‚¨áÔ∏è Export extracted content",
                                                    data=str(content).encode('utf-8', errors='ignore'),
                                                    file_name=f"{actual_name}_extracted_{s.get('type','content')}.txt",
                                                    mime="text/plain",
                                                    key=f"dl_stego_{key_prefix}_{uid}_{s.get('type','t')}"
                                                )
                            
                            st.markdown("---")
                with cat_tabs[0]:
                    render_list(apply_filters(files_list), key_prefix="all")
                with cat_tabs[1]:
                    render_list(apply_filters(files_list, categories['Images']), key_prefix="images")
                with cat_tabs[2]:
                    render_list(apply_filters(files_list, categories['Docs']), key_prefix="docs")
                with cat_tabs[3]:
                    render_list(apply_filters(files_list, categories['Archives']), key_prefix="archives")
                with cat_tabs[4]:
                    render_list(apply_filters(files_list, categories['Binaries']), key_prefix="binaries")
                with cat_tabs[5]:
                    render_list(apply_filters(files_list, categories['Audio/Video']), key_prefix="av")
                with cat_tabs[6]:
                    known = set().union(*categories.values())
                    filtered = [f for f in files_list if (f.get('ext') or f.get('extension','')).lower() not in known]
                    render_list(apply_filters(filtered), key_prefix="other")
                # Audio Spectrogram previews
                if results.get('voip_audio'):
                    has_spec = any(item.get('spectrogram_png') for item in results['voip_audio'])
                    if has_spec:
                        with st.expander("Audio Spectrograms"):
                            for i, item in enumerate(results['voip_audio']):
                                img_bytes = item.get('spectrogram_png')
                                if not img_bytes:
                                    continue
                                st.markdown(f"Session: {item.get('session_id','unknown')}  |  Sample Rate: {item.get('sample_rate','')} Hz")
                                st.image(img_bytes, caption=f"Spectrogram #{i+1}", use_container_width=True)
                                st.download_button(
                                    label="‚¨áÔ∏è Download Spectrogram",
                                    data=img_bytes,
                                    file_name=f"spectrogram_{i+1}.png",
                                    mime="image/png",
                                    key=f"dl_spec_{i}"
                                )

        # Replay Tab
        with tabs[8]:
            if results.get('replay_commands'):
                st.markdown("### üîÅ Replay Commands")
                st.info(f"Found {len(results['replay_commands'])} replay commands for traffic reconstruction")
                
                for i, cmd in enumerate(results['replay_commands'][:10], 1):
                    command = cmd.get('command', cmd.get('cmd', ''))
                    description = cmd.get('description', 'No description')
                    risk_level = cmd.get('risk_level', 'unknown')
                    protocol = cmd.get('protocol', 'Unknown')
                    
                    # Risk level styling
                    if risk_level == 'high':
                        risk_color = 'üî¥'
                    elif risk_level == 'medium':
                        risk_color = 'üü°'
                    else:
                        risk_color = 'üü¢'
                    
                    with st.expander(f"{i}. {description} [{protocol}] {risk_color}"):
                        st.markdown(f"**Description:** {description}")
                        st.markdown(f"**Protocol:** {protocol}")
                        st.markdown(f"**Risk Level:** {risk_level.title()}")
                        if cmd.get('src') and cmd.get('dst'):
                            st.markdown(f"**Source ‚Üí Destination:** {cmd['src']} ‚Üí {cmd['dst']}")
                        st.markdown("**Command:**")
                        st.code(command, language='bash')
            else:
                st.info("No replay commands available. This may occur if no sessions were reconstructed or traffic was encrypted.")

        # Crypto Tab
        with tabs[9]:
            st.markdown("### üõ°Ô∏è Crypto & Decoding")
            shown = False
            
            # JWT Tokens
            jwt_tokens = results.get('jwt_tokens', [])
            if jwt_tokens:
                shown = True
                st.markdown("#### JWT Tokens")
                for j in jwt_tokens[:20]:
                    with st.expander(f"JWT (frame {j.get('packet_index',0)+1})"):
                        st.markdown("**Header:**")
                        st.json(j.get('header', {}))
                        st.markdown("**Claims:**")
                        st.json(j.get('claims', {}))
                        st.markdown(f"Source: {j.get('src_ip','')} ‚Üí {j.get('dst_ip','')} | Protocol: {j.get('protocol','Unknown')}")
            
            # Decoded Data
            decoded_data = results.get('decoded_data', [])
            if decoded_data:
                shown = True
                st.markdown("#### Decoded Data")
                for d in decoded_data[:50]:
                    decoded_text = d.get('decoded', '') or d.get('result', '')
                    if decoded_text:
                        with st.expander(f"Decoded via {d.get('type','unknown')} (frame {(d.get('packet_index') or 0)+1})"):
                            st.code(decoded_text, language='text')
                            if d.get('poc'):
                                st.markdown("**PoC Steps:**")
                                for sidx, step in enumerate(d['poc'].get('extraction_steps', []), 1):
                                    st.write(f"{sidx}. {step.get('method','')}")
                                    if step.get('command'):
                                        st.code(step['command'], language='bash')
            
            # Check for base64 and other encoded content in findings
            encoded_findings = [f for f in results.get('findings', []) if 'base64' in f.get('type', '').lower() or 'encoded' in f.get('display_type', '').lower()]
            if encoded_findings and not decoded_data:
                shown = True
                st.markdown("#### Encoded Content in Findings")
                for f in encoded_findings[:10]:
                    with st.expander(f"Encoded Finding (packet {f.get('packet_index', 0)+1})"):
                        st.code(f.get('data', ''), language='text')
                        st.markdown(f"**Type:** {f.get('display_type', 'Unknown')}")
                        st.markdown(f"**Protocol:** {f.get('protocol', 'Unknown')}")
            
            # Encryption Attempts
            encryption_attempts = results.get('encryption_attempts', [])
            if encryption_attempts:
                shown = True
                st.markdown("#### Encryption/Decryption Attempts")
                for attempt in encryption_attempts:
                    with st.expander(f"Attempt: {attempt.get('method', 'Unknown')}"):
                        st.markdown(f"**Input:**")
                        st.code(attempt.get('input', ''), language="text")
                        st.markdown(f"**Output:**")
                        st.code(attempt.get('output', ''), language="text")
                        st.markdown(f"**Status:** {attempt.get('status', 'N/A')}")
                        if attempt.get('key'):
                            st.markdown(f"**Key/Password Used:** {attempt['key']}")
            
            if not shown:
                st.info("No crypto/decoding artifacts found. Try running analysis with encoded data or enable decryption options.")

        # AI Chat Tab - NEW FEATURE!
        with tabs[11]:
            st.markdown("### üí¨ Interactive AI Assistant")
            
            # Initialize conversation if needed
            if 'conversation_id' not in st.session_state:
                st.session_state.conversation_id = None
            if 'conversation_history' not in st.session_state:
                st.session_state.conversation_history = []
            if 'conversational_analyzer' not in st.session_state:
                try:
                    from conversational_analysis import create_conversational_analyzer
                    from ai_agent import AgentConfig, create_agent
                    
                    # Try to get AI agent for conversation
                    config = AgentConfig.load_config()
                    api_key = AgentConfig.get_api_key()
                    model = config.get('model', 'qwen/qwen3-235b-a22b:free')
                    
                    ai_agent = None
                    if api_key:
                        try:
                            ai_agent = create_agent(api_key, model)
                        except Exception:
                            pass
                    
                    st.session_state.conversational_analyzer = create_conversational_analyzer(ai_agent)
                except Exception as e:
                    st.session_state.conversational_analyzer = None
            
            conversational_analyzer = st.session_state.conversational_analyzer
            
            if conversational_analyzer:
                # Start conversation if not started
                if st.session_state.conversation_id is None:
                    try:
                        st.session_state.conversation_id = conversational_analyzer.start_conversation(
                            results, 
                            results.get('packet_data_list', [])
                        )
                        
                        # Get welcome message
                        history = conversational_analyzer.get_conversation_history(st.session_state.conversation_id)
                        if history:
                            st.session_state.conversation_history = history
                    except Exception as e:
                        st.error(f"Failed to start conversation: {str(e)}")
                
                # Chat interface
                if st.session_state.conversation_id:
                    # Display conversation history
                    st.markdown("#### üí¨ Conversation")
                    
                    # Create a container for chat messages
                    chat_container = st.container()
                    
                    with chat_container:
                        # Display conversation history
                        for msg in st.session_state.conversation_history:
                            role = msg.get('role', 'assistant')
                            content = msg.get('content', '')
                            timestamp = msg.get('timestamp', 0)
                            
                            if role == 'user':
                                with st.chat_message("user"):
                                    st.write(content)
                            else:
                                with st.chat_message("assistant"):
                                    st.write(content)
                                    
                                    # Show confidence if available
                                    confidence = msg.get('confidence')
                                    if confidence:
                                        st.caption(f"Confidence: {confidence * 100:.1f}%")
                    
                    # Chat input
                    st.markdown("---")
                    
                    # Suggested questions
                    st.markdown("**üí° Suggested Questions:**")
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        if st.button("üö© Explain the flags found", key="suggest_flags"):
                            user_input = "Can you explain the flags that were found in the analysis?"
                        else:
                            user_input = None
                    
                    with col2:
                        if st.button("üîê Security implications", key="suggest_security"):
                            user_input = "What are the security implications of these findings?"
                        else:
                            user_input = user_input if 'user_input' in locals() else None
                    
                    with col3:
                        if st.button("üìä Analysis summary", key="suggest_summary"):
                            user_input = "Give me a summary of the analysis results."
                        else:
                            user_input = user_input if 'user_input' in locals() else None
                    
                    # Text input for custom questions
                    if not user_input:
                        user_input = st.chat_input("Ask me anything about the analysis results...")
                    
                    # Process user input
                    if user_input:
                        try:
                            # Add user message to display
                            st.session_state.conversation_history.append({
                                'role': 'user',
                                'content': user_input,
                                'timestamp': time.time()
                            })
                            
                            # Get AI response
                            response_data = conversational_analyzer.process_user_message(
                                st.session_state.conversation_id, 
                                user_input
                            )
                            
                            if 'error' not in response_data:
                                # Add AI response to display
                                st.session_state.conversation_history.append({
                                    'role': 'assistant',
                                    'content': response_data.get('response', 'I\'m sorry, I couldn\'t generate a response.'),
                                    'timestamp': time.time(),
                                    'confidence': response_data.get('confidence')
                                })
                                
                                # Show follow-up suggestions if available
                                follow_ups = response_data.get('follow_up_suggestions', [])
                                if follow_ups:
                                    st.markdown("**Follow-up suggestions:**")
                                    for i, suggestion in enumerate(follow_ups[:3]):
                                        st.write(f"‚Ä¢ {suggestion}")
                                
                                # Trigger rerun to show new messages
                                st.rerun()
                            else:
                                st.error(f"Conversation error: {response_data['error']}")
                                
                        except Exception as e:
                            st.error(f"Failed to process message: {str(e)}")
                    
                    # Conversation controls
                    st.markdown("---")
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        if st.button("üîÑ Clear Conversation"):
                            st.session_state.conversation_history = []
                            st.session_state.conversation_id = None
                            st.rerun()
                    
                    with col2:
                        if st.button("üìÑ Export Conversation"):
                            conversation_export = {
                                'timestamp': time.time(),
                                'messages': st.session_state.conversation_history,
                                'analysis_summary': {
                                    'total_packets': results.get('total_packets', 0),
                                    'findings': len(results.get('findings', [])),
                                    'ai_findings': len(results.get('ai_findings', []))
                                }
                            }
                            
                            import json
                            st.download_button(
                                label="üì• Download Conversation",
                                data=json.dumps(conversation_export, indent=2),
                                file_name=f"flagsniff_conversation_{int(time.time())}.json",
                                mime="application/json"
                            )
                
                else:
                    st.warning("‚ö†Ô∏è Failed to initialize conversation. Please try refreshing the page.")
                    
            else:
                # Fallback interface when conversational analyzer is not available
                st.info("ü§ñ **AI Chat Not Available**")
                st.markdown("""The conversational AI feature requires:
                
                1. **AI Agent Configuration** - Configure your API key in the AI Config page
                2. **Analysis Results** - Complete an analysis to provide context for the chat
                3. **Conversational Analysis Module** - Ensure all dependencies are installed
                
                **Available AI Features:**
                - ü§ñ **Standard AI Analysis** - Available in the AI tab
                - üìä **AI Insights** - Shown with analysis results
                - üí° **AI Suggestions** - Contextual recommendations
                """)
                
                # Show current AI configuration status
                try:
                    from ai_agent import AgentConfig
                    config = AgentConfig.load_config()
                    api_key = AgentConfig.get_api_key()
                    
                    if api_key:
                        st.success("‚úÖ AI Agent is configured")
                        st.info(f"Current model: `{config.get('model', 'Unknown')}`")
                    else:
                        st.warning("üîë No API key configured. Go to AI Config page to set up.")
                        
                except Exception as e:
                    st.error(f"AI configuration error: {str(e)}")
        
        # Export Tab
        with tabs[12]:
            st.markdown("### üì• Export Results")
            col1, col2, col3 = st.columns(3)
            with col1:
                if st.button("üìÑ Export JSON", use_container_width=True):
                    export_results(results, "json")
            with col2:
                if st.button("üìä Export CSV", use_container_width=True):
                    export_results(results, "csv")
            with col3:
                if st.button("üìã Export HTML", use_container_width=True):
                    export_results(results, "html")

        # Early return to avoid legacy layout duplication
        st.markdown('</div>', unsafe_allow_html=True)
        return
    
    else:
        st.markdown("""
        <div style="text-align: center; padding: 4rem 2rem;">
            <div style="font-size: 4rem; margin-bottom: 1rem;">üìä</div>
            <div style="font-size: 1.5rem; font-weight: 600; margin-bottom: 1rem;">No Results Yet</div>
            <div style="color: rgba(255, 255, 255, 0.7);">Run an analysis to see results here</div>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown('</div>', unsafe_allow_html=True)

def render_advanced_page():
    """Render advanced features page"""
    st.markdown('<div class="glass-card">', unsafe_allow_html=True)
    
    st.markdown("### üöÄ Advanced Features & Multi-Agent System")
    
    if not IMPORTS_OK:
        st.error("Advanced features unavailable - Import error detected")
        st.markdown('</div>', unsafe_allow_html=True)
        return
    
    # Initialize systems if not already done
    if not st.session_state.multi_agent_system:
        try:
            api_key = AgentConfig.get_api_key()
            if api_key:
                st.session_state.multi_agent_system = MultiAgentSystem(api_key)
                st.success("‚úÖ Multi-Agent System initialized!")
            else:
                st.warning("‚ö†Ô∏è Configure AI API key to enable multi-agent system")
        except Exception as e:
            st.error(f"Failed to initialize multi-agent system: {e}")
    
    if not st.session_state.workflow_orchestrator:
        try:
            st.session_state.workflow_orchestrator = WorkflowOrchestrator()
            st.success("‚úÖ Workflow Orchestrator initialized!")
        except Exception as e:
            st.error(f"Failed to initialize workflow orchestrator: {e}")
    
    # Multi-Agent System Status
    st.markdown("#### ü§ñ Multi-Agent System Status")
    
    if st.session_state.multi_agent_system:
        agent_cols = st.columns(5)
        
        with agent_cols[0]:
            st.markdown("""
            <div style="text-align: center; padding: 1rem; background: rgba(0, 245, 255, 0.1); border-radius: 15px;">
                <div style="font-size: 2rem;">üéØ</div>
                <div style="font-weight: 600;">Flag Hunter</div>
                <div style="font-size: 0.8rem;">Active</div>
            </div>
            """, unsafe_allow_html=True)
        
        with agent_cols[1]:
            st.markdown("""
            <div style="text-align: center; padding: 1rem; background: rgba(255, 0, 255, 0.1); border-radius: 15px;">
                <div style="font-size: 2rem;">üîç</div>
                <div style="font-weight: 600;">Forensics</div>
                <div style="font-size: 0.8rem;">Active</div>
            </div>
            """, unsafe_allow_html=True)
        
        with agent_cols[2]:
            st.markdown("""
            <div style="text-align: center; padding: 1rem; background: rgba(0, 255, 136, 0.1); border-radius: 15px;">
                <div style="font-size: 2rem;">üîê</div>
                <div style="font-weight: 600;">Crypto</div>
                <div style="font-size: 0.8rem;">Active</div>
            </div>
            """, unsafe_allow_html=True)
        
        with agent_cols[3]:
            st.markdown("""
            <div style="font-size: 2rem;">üåê</div>
            <div style="font-weight: 600;">Network</div>
            <div style="font-size: 0.8rem;">Active</div>
            """, unsafe_allow_html=True)
        
        with agent_cols[4]:
            st.markdown("""
            <div style="font-size: 2rem;">ü¶†</div>
            <div style="font-weight: 600;">Malware</div>
            <div style="font-size: 0.8rem;">Active</div>
            """, unsafe_allow_html=True)
    
    # AI Monitor
    st.markdown("#### üìä AI Activity Monitor")
    
    if st.session_state.ai_monitor:
        st.session_state.ai_monitor.display_monitor(st.container())
    
    # Workflow Orchestrator
    st.markdown("#### üîÑ Workflow Orchestrator")
    
    if st.session_state.workflow_orchestrator:
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("üöÄ Create Network CTF Workflow", use_container_width=True):
                try:
                    # Initialize required components for workflow
                    from utils.parsers import PacketParser
                    from utils.patterns import PatternMatcher
                    from ctf_analyzer import NetworkTrafficDecoder, EncodingDecoder, CTFAnalyzer
                    
                    packet_parser = PacketParser()
                    pattern_matcher = PatternMatcher()
                    network_decoder = NetworkTrafficDecoder()
                    encoding_decoder = EncodingDecoder()
                    ctf_analyzer = CTFAnalyzer()
                    
                    # Create workflow with proper components
                    workflow = create_network_ctf_workflow(
                        st.session_state.workflow_orchestrator,
                        packet_parser,
                        pattern_matcher,
                        network_decoder,
                        encoding_decoder,
                        ctf_analyzer
                    )
                    st.success("‚úÖ Network CTF workflow created!")
                except Exception as e:
                    st.error(f"Failed to create workflow: {e}")
        
        with col2:
            if st.button("üìã View Active Workflows", use_container_width=True):
                workflows = st.session_state.workflow_orchestrator.list_workflows()
                if workflows:
                    st.write("Active workflows:", workflows)
                else:
                    st.info("No active workflows")
    
    # CTF Visualizations
    st.markdown("#### üìà CTF Analysis Visualizations")
    
    if st.session_state.ctf_visualizer and st.session_state.analysis_results:
        results = st.session_state.analysis_results
        
        if results.get('findings'):
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**Findings Distribution**")
                fig = st.session_state.ctf_visualizer.create_findings_distribution(results['findings'])
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                st.markdown("**Confidence Heatmap**")
                fig = st.session_state.ctf_visualizer.create_confidence_heatmap(results['findings'])
                st.plotly_chart(fig, use_container_width=True)
    
    st.markdown('</div>', unsafe_allow_html=True)

def render_about_page():

    """Render about page"""
    st.markdown('<div class="glass-card">', unsafe_allow_html=True)
    
    st.markdown("### ‚ö° About FlagSniff Pro")
    
    st.markdown("""
    **FlagSniff Pro** is a next-generation PCAP analysis tool designed for security professionals, 
    red team operators, and CTF players. Built with cutting-edge AI technology and modern web interfaces.
    
    #### üöÄ Key Features
    - **AI-Powered Analysis**: Advanced machine learning for pattern recognition
    - **Real-time Processing**: Lightning-fast analysis of network captures
    - **Modern Interface**: Sleek, responsive design with dark/light themes
    - **Multiple AI Models**: Choose from 10+ state-of-the-art AI models
    - **Export Options**: JSON, CSV, and HTML report generation
    - **Multi-Agent System**: 5 specialized AI agents working together
    - **Workflow Orchestration**: Automated multi-step analysis pipelines
    - **Advanced Visualizations**: Interactive charts and network graphs
    - **Real-time AI Monitoring**: Live tracking of AI agent activities
    
    #### üéØ Supported Analysis
    - CTF flag detection with advanced patterns
    - Credential extraction from network traffic
    - API token and authentication data discovery
    - Protocol security assessment
    - Steganography and covert channel detection
    - Multi-layer encoding analysis
    - Behavioral pattern recognition
    - Threat intelligence correlation
    
    #### ü§ñ AI Models & Agents
    - **Claude 3.5 Sonnet**: Best overall performance
    - **GPT-4 Turbo**: Creative analysis and insights
    - **Gemini Pro**: Fast and efficient processing
    - **Llama 3.1**: Open-source power
    - **Flag Hunter Agent**: Specialized CTF analysis
    - **Forensics Agent**: Evidence analysis
    - **Crypto Agent**: Encryption analysis
    - **Network Security Agent**: Security assessment
    - **Malware Analysis Agent**: Threat detection
    
    #### üìä Version Information
    - **Version**: 3.0 (Enhanced with Multi-Agent System)
    - **Author**: Waleed
    """)
    
    st.markdown('</div>', unsafe_allow_html=True)

def run_analysis(uploaded_file, search_options, custom_regex, ai_mode, ai_enabled, confidence_threshold, ctf_context=None, user_decrypt_key=None):
    """Run the analysis with enhanced terminal-style progress tracking"""
    if not IMPORTS_OK:
        st.error("Analysis unavailable - Import error detected")
        return
    
    # Save file temporarily
    with tempfile.NamedTemporaryFile(delete=False, suffix='.pcap') as tmp_file:
        tmp_file.write(uploaded_file.getvalue())
        tmp_file_path = tmp_file.name
    
    # Single progress modal container
    progress_placeholder = st.empty()
    
    class SimpleProgress:
        def __init__(self, placeholder):
            self.placeholder = placeholder
            self.start_time = time.time()
            self.last_update = time.time()
            self.current_phase = ""
            self.phase_times = {
                "Initialization": 2,
                "PCAP Validation": 3, 
                "Packet Parsing": 8,
                "Pattern Analysis": 12,
                "CTF Analysis": 15,
                "AI Processing": 18,
                "Report Generation": 4
            }
            self.total_estimated_time = sum(self.phase_times.values())
            self.last_message = ""
            self.phase_start_time = time.time()
            self.update_counter = 0
            
            # Initialize session state for progress tracking
            if 'analysis_running' not in st.session_state:
                st.session_state.analysis_running = False
            if 'force_refresh' not in st.session_state:
                st.session_state.force_refresh = 0
            
        def force_ui_refresh(self):
            """Force a UI refresh by incrementing the refresh counter"""
            st.session_state.force_refresh = st.session_state.get('force_refresh', 0) + 1
            # Don't use st.rerun() during analysis as it interrupts the process
            
        def should_update(self):
            """Check if enough time has passed for an update"""
            return True  # Always allow updates for immediate responsiveness
            
        def log(self, message, level="INFO"):
            self.last_message = message
            self.update_counter += 1
            self.update_display()
            
        def set_phase(self, phase_name):
            self.current_phase = phase_name
            self.phase_start_time = time.time()
            self.log(f"Starting {phase_name}...")
            
        def update_display(self):
            current_time = time.time()
            self.last_update = current_time
            elapsed = current_time - self.start_time
            
            # Calculate progress based on phases
            phase_keys = list(self.phase_times.keys())
            current_phase_idx = phase_keys.index(self.current_phase) if self.current_phase in phase_keys else 0
            
            # Calculate progress percentage
            completed_phases_time = sum(self.phase_times[phase] for phase in phase_keys[:current_phase_idx])
            current_phase_time = self.phase_times.get(self.current_phase, 5)
            current_phase_elapsed = min(current_time - self.phase_start_time, current_phase_time)
            
            total_elapsed_time = completed_phases_time + current_phase_elapsed
            progress_percent = min(100, (total_elapsed_time / self.total_estimated_time) * 100)
            remaining = max(0, self.total_estimated_time - total_elapsed_time)
            
            # Store progress in session state for persistence
            st.session_state.progress_data = {
                'elapsed': elapsed,
                'progress': progress_percent,
                'remaining': remaining,
                'phase': self.current_phase,
                'message': self.last_message,
                'update_counter': self.update_counter
            }
            
            # Get phase-specific details
            phase_info = {
                "Initialization": {"icon": "üöÄ", "desc": "Setting up analysis environment"},
                "PCAP Validation": {"icon": "üîç", "desc": "Validating PCAP structure and integrity"},
                "Packet Parsing": {"icon": "üì¶", "desc": "Extracting and parsing network packets"},
                "Pattern Analysis": {"icon": "üîé", "desc": "Analyzing patterns and extracting findings"},
                "CTF Analysis": {"icon": "üéØ", "desc": "Running CTF-specific analysis and flag detection"},
                "AI Processing": {"icon": "üß†", "desc": "AI-powered analysis and enhancement"},
                "Report Generation": {"icon": "üìä", "desc": "Compiling final analysis report"}
            }
            
            current_info = phase_info.get(self.current_phase, {"icon": "‚öôÔ∏è", "desc": "Processing..."})
            
            # Always clear and update the placeholder
            self.placeholder.empty()
            with self.placeholder.container():
                # Title with icon and live indicator
                st.markdown(f"### {current_info['icon']} FlagSniff Analysis Engine üî¥ LIVE")
                
                # Current phase with time indicator
                phase_elapsed = current_time - self.phase_start_time
                st.markdown(f"**{self.current_phase or 'Initializing...'} ({phase_elapsed:.1f}s)**")
                
                # Progress bar using Streamlit's native progress bar
                st.progress(progress_percent / 100, text=f"Progress: {progress_percent:.1f}% ‚Ä¢ Update #{self.update_counter}")
                
                # Stats in columns
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("‚è±Ô∏è Elapsed", f"{elapsed:.1f}s")
                
                with col2:
                    st.metric("üìà Progress", f"{progress_percent:.1f}%")
                
                with col3:
                    st.metric("üïí Remaining", f"{remaining:.1f}s")
                
                # Current task info with timestamp
                if self.last_message:
                    timestamp = time.strftime("%H:%M:%S", time.localtime())
                    st.info(f"**Status:** {self.last_message} *({timestamp})*")
                
                # Show phase progress
                phase_progress = min(100, (phase_elapsed / current_phase_time) * 100)
                st.caption(f"Phase Progress: {phase_progress:.1f}%")
        
        def clear_display(self):
            """Clear the progress modal when analysis is complete"""
            # Mark analysis as complete
            st.session_state.analysis_running = False
            st.session_state.analysis_complete = True
            
            # Show completion message briefly
            with self.placeholder.container():
                st.success("‚úÖ Analysis Complete! Redirecting to results...")
                st.balloons()
            
            # Use session state to trigger clear on next rerun instead of threading
            st.session_state.clear_progress_display = True
    
    # Initialize simple progress with placeholder
    progress = SimpleProgress(progress_placeholder)
    
    # Mark analysis as running and show initial progress
    st.session_state.analysis_running = True
    st.session_state.analysis_start_time = time.time()
    
    # Show initial progress display immediately
    progress.set_phase("Initialization")
    progress.log("Analysis starting...")
    
    try:
        # Initialize analyzer
        progress.log("Initializing WebPcapAnalyzer...")
        analyzer = WebPcapAnalyzer()
        
        # Validate analyzer dependencies
        progress.set_phase("PCAP Validation")
        try:
            progress.log("Validating analyzer dependencies...")
            
            # Test if critical components are available
            from utils.parsers import PacketParser
            from utils.patterns import PatternMatcher
            parser_test = PacketParser()
            pattern_test = PatternMatcher()
            
            progress.log("Core dependencies validated successfully")
            
        except ImportError as dep_error:
            progress.log(f"Missing required dependencies: {str(dep_error)}")
            progress.log("Analyzer requires utils.parsers and utils.patterns modules")
            return
        except Exception as dep_error:
            progress.log(f"Dependency validation warning: {str(dep_error)}")
            progress.log("Continuing with analysis, some features may be limited")
        
        # Validate PCAP file before analysis
        try:
            from scapy.all import rdpcap
            # Test if we can read the PCAP file
            test_packets = rdpcap(tmp_file_path)
            if len(test_packets) == 0:
                progress.log("PCAP file is empty or contains no valid packets")
                return
            progress.log(f"PCAP file validation: {len(test_packets)} packets found")
        except Exception as pcap_error:
            progress.log(f"Invalid PCAP file: {str(pcap_error)}")
            progress.log("Please ensure the uploaded file is a valid PCAP/PCAPNG file")
            return
        
        # Perform analysis with detailed error tracking
        progress.set_phase("Packet Parsing")
        try:
            progress.log("Starting detailed analysis phases...")
            
            # Phase 1: Initialize analyzer
            try:
                progress.log("Phase 1: Initializing analyzer components...")
                results = None  # Initialize to track progress
                
                # Test core analyzer functionality step by step
                progress.log("Creating analyzer instance...")
                
                progress.log("Testing analyzer methods...")
                
                analyzer_result = analyzer.analyze_file(tmp_file_path, search_options, custom_regex, user_decrypt_key)
                progress.log("Phase 1: Analyzer initialization successful")
                results = analyzer_result
                
            except ImportError as import_err:
                progress.log(f"Phase 1 failed - Import Error: {str(import_err)}")
                progress.log("Missing dependencies. Please check if all required packages are installed.")
                return
            except AttributeError as attr_err:
                progress.log(f"Phase 1 failed - Attribute Error: {str(attr_err)}")
                progress.log("This suggests a missing method or property in the analyzer components.")
                return
            except Exception as phase1_err:
                progress.log(f"Phase 1 failed - Analysis Error: {str(phase1_err)}")
                progress.log(f"Error type: {type(phase1_err).__name__}")
                progress.log("Attempting fallback analysis mode...")
                
                # Fallback: Basic analysis without advanced features
                try:
                    from scapy.all import rdpcap
                    packets = rdpcap(tmp_file_path)
                    
                    # Create minimal results structure
                    results = {
                        'total_packets': len(packets),
                        'analyzed_packets': len(packets),
                        'findings': [],
                        'statistics': {
                            'total_packets': len(packets),
                            'protocols': {}
                        },
                        'file_info': {
                            'name': 'uploaded_file.pcap',
                            'size': os.path.getsize(tmp_file_path)
                        },
                        'analysis_time': {'duration': 'fallback_mode'},
                        'ctf_analysis': {
                            'flag_candidates': [],
                            'metadata': {
                                'analysis_mode': 'fallback',
                                'total_findings': 0
                            }
                        }
                    }
                    
                    progress.log("Fallback analysis completed - basic packet counting successful")
                    progress.log("Note: Advanced analysis features are unavailable in fallback mode")
                    
                except Exception as fallback_err:
                    progress.log(f"Fallback analysis also failed: {str(fallback_err)}")
                    return
                
        except Exception as analyzer_error:
            progress.log(f"Analysis failed during execution: {str(analyzer_error)}")
            progress.log(f"Error type: {type(analyzer_error).__name__}")
            return
        
        # Ensure results is not None
        if results is None:
            progress.log("Analysis failed: analyzer returned no results")
            progress.log("This could indicate empty/corrupted PCAP or processing error")
            return
        
        # Ensure results is a dictionary
        if not isinstance(results, dict):
            progress.log(f"Analysis failed: invalid results format (got {type(results)})")
            return
        
        # Initialize required keys if missing
        if 'findings' not in results:
            results['findings'] = []
            
        # Validate that we have at least basic results structure
        required_keys = ['total_packets', 'analyzed_packets', 'findings']
        missing_keys = [key for key in required_keys if key not in results]
        if missing_keys:
            progress.log(f"Analysis incomplete: missing result keys: {missing_keys}")
            # Initialize missing keys with defaults
            if 'total_packets' not in results:
                results['total_packets'] = 0
            if 'analyzed_packets' not in results:
                results['analyzed_packets'] = 0
        
        # CTF Analysis phase
        progress.set_phase("CTF Analysis")
        try:
            progress.log("Starting CTF-specific analysis...")
            
            # Get packet data for CTF analysis
            packet_data_list = results.get('packet_data_list', [])
            progress.log(f"Processing {len(packet_data_list)} packet data records")
            
            if packet_data_list:
                from utils.parsers import PacketParser
                from utils.patterns import PatternMatcher
                from ctf_analyzer import NetworkTrafficDecoder, EncodingDecoder, CTFAnalyzer
                
                progress.log("Initializing CTF analyzer components...")
                ctf_analyzer = CTFAnalyzer()
                progress.log("CTF analyzer initialized")
                
                progress.log("Running comprehensive CTF analysis...")
                # Run CTF analysis (remove DEBUG output)
                ctf_results = ctf_analyzer.analyze(packet_data_list, challenge_type='network')
                
                progress.log("Processing CTF analysis results...")
                # Log CTF analysis results (clean output)
                if ctf_results:
                    patterns_count = len(ctf_results.get('patterns', []))
                    findings_count = len(ctf_results.get('findings', []))
                    progress.log(f"CTF Analysis complete: {patterns_count} patterns, {findings_count} findings")
                    
                    if ctf_results.get('http_analysis'):
                        http_analysis = ctf_results['http_analysis']
                        first_letters = len(http_analysis.get('first_letters', []))
                        progress.log(f"HTTP Analysis: {first_letters} first letter patterns found")
                        
                results['ctf_analysis'] = ctf_results
                

                progress.log("CTF analysis integration complete")
            else:
                progress.log("No packet data available for CTF analysis")
                
        except Exception as ctf_error:
            progress.log(f"CTF analysis failed: {str(ctf_error)}")
            results['ctf_analysis'] = {'error': str(ctf_error)}
        
        # Advanced Steganography Analysis
        progress.set_phase("Advanced Steganography")
        try:
            progress.log("Starting advanced steganography analysis...")
            
            # Initialize steganography detector
            if st.session_state.steganography_detector:
                progress.log("Running comprehensive steganography detection...")
                
                # Get packets and packet data for steganography analysis
                packets = results.get('packets', [])
                packet_data_list = results.get('packet_data_list', [])
                
                # Run steganography analysis
                stego_results = st.session_state.steganography_detector.analyze_all_steganography(
                    packets, packet_data_list
                )
                
                if stego_results:
                    results['steganography_analysis'] = stego_results
                    
                    # Count findings
                    total_stego_findings = (
                        len(stego_results.get('image_steganography', [])) +
                        len(stego_results.get('audio_steganography', [])) +
                        len(stego_results.get('file_signature_analysis', [])) +
                        len(stego_results.get('timing_patterns', [])) +
                        len(stego_results.get('size_patterns', []))
                    )
                    
                    progress.log(f"Steganography analysis complete: {total_stego_findings} findings")
                    
                    # Log specific findings
                    if stego_results.get('image_steganography'):
                        progress.log(f"Found {len(stego_results['image_steganography'])} image steganography findings")
                    if stego_results.get('file_signature_analysis'):
                        progress.log(f"Found {len(stego_results['file_signature_analysis'])} file signature anomalies")
                        
                else:
                    progress.log("Steganography analysis returned no results")
            else:
                progress.log("Steganography detector not available - skipping advanced analysis")
                
        except Exception as stego_error:
            progress.log(f"Steganography analysis failed: {str(stego_error)}")
            results['steganography_analysis'] = {'error': str(stego_error)}
        
        # Advanced CTF Challenge Solver
        progress.set_phase("CTF Challenge Solver")
        try:
            progress.log("Starting advanced CTF challenge solver...")
            
            # Import and initialize advanced CTF solver
            from ctf_analyzer import create_advanced_ctf_solver
            
            progress.log("Initializing advanced CTF solver...")
            ctf_solver = create_advanced_ctf_solver()
            
            # Prepare challenge data
            challenge_data = {
                'data': str(results.get('packet_data_list', [])),
                'packet_data_list': results.get('packet_data_list', []),
                'packets': results.get('packets', []),
                'findings': results.get('findings', []),
                'file_type': 'pcap'
            }
            
            progress.log("Running automated challenge solving...")
            
            # Run automated challenge solving
            solver_results = ctf_solver.auto_solve_challenge(challenge_data, ctf_context)
            
            if solver_results:
                results['ctf_solver_analysis'] = solver_results
                
                # Log solver results
                challenge_type = solver_results.get('challenge_type', 'unknown')
                flags_found = len(solver_results.get('flags_found', []))
                techniques_used = len(solver_results.get('techniques_used', []))
                confidence = solver_results.get('confidence', 0)
                
                progress.log(f"CTF Solver complete: Type={challenge_type}, Flags={flags_found}, Confidence={confidence}%")
                
                if flags_found > 0:
                    progress.log(f"üéâ Automatically found {flags_found} flags using challenge solver!")
                    for flag in solver_results['flags_found']:
                        progress.log(f"üèÜ Auto-solved flag: {flag[:50]}...")
                
                if techniques_used > 0:
                    progress.log(f"Applied {techniques_used} solving techniques")
                    
            else:
                progress.log("CTF solver returned no results")
                
        except Exception as solver_error:
            progress.log(f"CTF solver analysis failed: {str(solver_error)}")
            results['ctf_solver_analysis'] = {'error': str(solver_error)}
        
        # AI Analysis if enabled
        progress.log(f"DEBUG: Checking AI analysis conditions...")
        progress.log(f"DEBUG: ai_enabled = {ai_enabled}")
        progress.log(f"DEBUG: ai_mode = '{ai_mode}'")
        progress.log(f"DEBUG: ai_mode != 'Standard Only' = {ai_mode != 'üìä Standard Only'}")
        progress.log(f"DEBUG: Overall condition = {ai_enabled and ai_mode != 'üìä Standard Only'}")
        
        if ai_enabled and ai_mode != "üìä Standard Only":
            # Store AI mode for debugging
            st.session_state.last_ai_mode = ai_mode
            
            progress.set_phase("AI Processing")
            progress.log("üöÄ ENTERING AI ANALYSIS SECTION")
            try:
                progress.log("Initializing AI analysis...")
                config = AgentConfig.load_config()
                model = config.get('model', 'qwen/qwen3-235b-a22b:free')
                api_key = config.get('openrouter_api_key')
                
                # Check if current model is rate limited or unavailable
                rate_handler = st.session_state.rate_limit_handler
                if model in rate_handler.rate_limit_errors:
                    progress.log(f"Model '{model}' is rate limited. Switching to offline analysis mode.")
                    ai_enabled = False
                    results['ai_status'] = 'rate_limited'
                    results['ai_error'] = f"Model {model} is rate limited. Offline analysis completed successfully."
                else:
                    progress.log(f"Creating AI agent with model: {model}")
                    
                    # Try to create agent with fallback logic
                    agent = None
                    models_to_try = [model] + [m for m in rate_handler.fallback_models if m != model][:3]
                    
                    for attempt_model in models_to_try:
                        try:
                            agent = create_agent(api_key, attempt_model)
                            if agent:
                                if attempt_model != model:
                                    progress.log(f"Switched to fallback model: {attempt_model}")
                                    results['ai_fallback_model'] = attempt_model
                                break
                        except Exception as model_error:
                            error_msg = str(model_error)
                            if "404" in error_msg or "not found" in error_msg.lower():
                                progress.log(f"Model {attempt_model} not available, trying next...")
                                rate_handler.handle_rate_limit(attempt_model, f"Model not found: {error_msg}")
                                continue
                            else:
                                progress.log(f"Error with model {attempt_model}: {error_msg}")
                                continue
                    if agent:
                        agent.set_confidence_thresholds(
                            min_confidence=confidence_threshold,
                            flag_threshold=max(confidence_threshold, 85),
                            credential_threshold=max(confidence_threshold, 90)
                        )
                        progress.log("AI agent configured with confidence thresholds")
                        
                        with open(tmp_file_path, 'rb') as f:
                            raw_data = f.read()
                        packet_text = raw_data.decode('utf-8', errors='ignore')[:15000]
                        progress.log(f"Processing {len(packet_text)} characters of packet data")
                        
                        # Run AI analysis based on mode
                        if "Enhanced Analysis" in ai_mode:
                            # Use comprehensive AI analysis for Enhanced mode
                            comprehensive_analysis = agent.comprehensive_ai_analysis(
                                packet_data=packet_text,
                                findings=results.get('findings', []),
                                ctf_context=ctf_context,
                                user_question=None,
                                conversation_history=None
                            )
                            
                            if comprehensive_analysis and isinstance(comprehensive_analysis, dict) and 'error' not in comprehensive_analysis:
                                results['comprehensive_ai_analysis'] = comprehensive_analysis
                                progress.log("Comprehensive AI analysis completed successfully")
                                
                                # Extract AI findings from comprehensive analysis
                                ai_findings = []
                                
                                # Extract from specialist analysis
                                if comprehensive_analysis.get('specialist_analysis'):
                                    for specialist_result in comprehensive_analysis['specialist_analysis']:
                                        if specialist_result.get('ai_findings'):
                                            ai_findings.extend(specialist_result['ai_findings'])
                                
                                # Extract from validated findings
                                if comprehensive_analysis.get('validated_findings'):
                                    for finding in comprehensive_analysis['validated_findings']:
                                        if finding.get('ai_analysis'):
                                            ai_findings.append({
                                                'flag_candidate': finding.get('data', ''),
                                                'confidence': finding['ai_analysis'].get('confidence', 0),
                                                'reasoning': finding['ai_analysis'].get('explanation', ''),
                                                'source': 'comprehensive_analysis'
                                            })
                                
                                # Extract from flag reconstruction
                                if comprehensive_analysis.get('flag_reconstruction', {}).get('reconstructed_flags'):
                                    for flag in comprehensive_analysis['flag_reconstruction']['reconstructed_flags']:
                                        ai_findings.append({
                                            'flag_candidate': flag.get('flag', ''),
                                            'confidence': flag.get('confidence', 0),
                                            'reasoning': f"Flag reconstructed using {flag.get('reconstruction_method', 'advanced techniques')}",
                                            'source': 'flag_reconstruction'
                                        })
                                
                                progress.log(f"Extracted {len(ai_findings)} AI findings from comprehensive analysis")
                            else:
                                progress.log("Comprehensive analysis failed, falling back to hunt_hidden_flags")
                                ai_findings = agent.hunt_hidden_flags(packet_text, ai_mode)
                        else:
                            # Use specialized analysis for other modes
                            ai_findings = agent.hunt_hidden_flags(packet_text, ai_mode)
                        
                        if ai_findings and isinstance(ai_findings, list):
                            # Filter AI findings with improved logic
                            quality_findings = []
                            for finding in ai_findings:
                                confidence = finding.get('confidence', 0)
                                flag_candidate = finding.get('flag_candidate', '')
                                
                                # Apply improved quality filters - less strict
                                if confidence >= 70 and len(flag_candidate) > 3:  # Reduced from 85 and 10
                                    # Enhanced pattern check - more flexible
                                    if ('{' in flag_candidate and '}' in flag_candidate) or \
                                       ('flag' in flag_candidate.lower()) or \
                                       ('ctf' in flag_candidate.lower()) or \
                                       ('htb' in flag_candidate.lower()) or \
                                       ('picoctf' in flag_candidate.lower()) or \
                                       re.search(r'[A-Za-z0-9_]{2,15}\{[A-Za-z0-9_\-!@#$%^&*()+=]{3,}\}', flag_candidate):
                                        quality_findings.append(finding)
                                elif confidence >= 60 and len(flag_candidate) > 8:  # Additional tier for medium confidence
                                    # Even broader pattern for decent confidence findings
                                    if ('{' in flag_candidate and '}' in flag_candidate) or \
                                       any(keyword in flag_candidate.lower() for keyword in ['flag', 'ctf', 'user', 'pass', 'token', 'key']):
                                        quality_findings.append(finding)
                            
                            results['ai_findings'] = quality_findings
                            if quality_findings:
                                results['ai_status'] = 'success'
                                progress.log(f"AI Analysis complete: {len(quality_findings)} high-quality findings")
                            else:
                                results['ai_status'] = 'no_results'
                                progress.log("AI analysis completed - no findings passed quality filters")
                        
                        # Set AI status based on comprehensive analysis if available
                        elif results.get('comprehensive_ai_analysis'):
                            comprehensive = results['comprehensive_ai_analysis']
                            if comprehensive.get('validated_findings') or comprehensive.get('specialist_analysis') or comprehensive.get('flag_reconstruction'):
                                results['ai_status'] = 'comprehensive_success'
                                progress.log("Comprehensive AI analysis completed with results")
                            else:
                                results['ai_status'] = 'comprehensive_no_results'
                                progress.log("Comprehensive AI analysis completed - no significant findings")
                    else:
                        progress.log("AI agent creation failed")
                        results['ai_findings'] = []
                        results['ai_status'] = 'agent_failed'
                        
            except Exception as ai_error:
                progress.log(f"AI analysis failed: {str(ai_error)}")
                results['ai_status'] = 'failed'
                results['ai_error'] = str(ai_error)
        else:
            # AI disabled or Standard Only mode - set appropriate status
            if not ai_enabled:
                results['ai_status'] = 'disabled'
                results['ai_error'] = 'AI is disabled - no API key configured'
            else:
                results['ai_status'] = 'standard_only'
                results['ai_error'] = 'Standard analysis mode selected - AI analysis skipped'
            
            # Always provide some AI suggestions for offline analysis
            st.session_state.last_ai_mode = ai_mode
            results['ai_suggestions'] = [
                "üìä **Analysis Status**: Standard analysis completed without AI enhancement",
                "üîç **Pattern Matching**: Use regex patterns and custom searches for specific targets",
                "üîç **Protocol Analysis**: Review packet details in the Packets tab for manual analysis",
                "üìÅ **File Extraction**: Check the Files tab for any carved or extracted content",
                "üóìÔ∏è **Timeline Review**: Use the Timeline tab to identify suspicious activity patterns"
            ]
        
        # Final phase - Report Generation
        progress.set_phase("Report Generation")
        progress.log("Generating analysis report...")
        
        # CRITICAL: Ensure AI status is ALWAYS set (following memory requirements)
        if 'ai_status' not in results:
            if not ai_enabled:
                results['ai_status'] = 'disabled'
                results['ai_error'] = 'AI is disabled - no API key configured'
                results['ai_suggestions'] = [
                    "üìä **Analysis Status**: Standard analysis completed without AI enhancement",
                    "üîç **Pattern Matching**: Use regex patterns and custom searches for specific targets",
                    "üîç **Protocol Analysis**: Review packet details in the Packets tab for manual analysis",
                    "üìÅ **File Extraction**: Check the Files tab for any carved or extracted content",
                    "üóΩ **Timeline Review**: Use the Timeline tab to identify suspicious activity patterns"
                ]
                st.session_state.last_ai_mode = ai_mode
            elif ai_mode == "üìä Standard Only":
                results['ai_status'] = 'standard_only'
                results['ai_error'] = 'Standard analysis mode selected - AI analysis skipped'
                results['ai_suggestions'] = [
                    "üìä **Analysis Status**: Standard analysis completed without AI enhancement",
                    "üîç **Pattern Matching**: Use regex patterns and custom searches for specific targets",
                    "üîç **Protocol Analysis**: Review packet details in the Packets tab for manual analysis",
                    "üìÅ **File Extraction**: Check the Files tab for any carved or extracted content",
                    "üóΩ **Timeline Review**: Use the Timeline tab to identify suspicious activity patterns"
                ]
                st.session_state.last_ai_mode = ai_mode
            else:
                results['ai_status'] = 'unknown'
                results['ai_error'] = 'AI analysis state unknown'
                results['ai_suggestions'] = ["Please check AI configuration and re-run analysis"]
                st.session_state.last_ai_mode = ai_mode
        
        # Ensure ai_findings exists
        if 'ai_findings' not in results:
            results['ai_findings'] = []
        
        # Ensure ai_suggestions exists
        if 'ai_suggestions' not in results:
            results['ai_suggestions'] = ["No AI suggestions available"]
        
        # Final summary
        total_findings = len(results.get('findings', []))
        ai_findings_count = len(results.get('ai_findings', []))
        total_packets = results.get('total_packets', 0)
        
        progress.log(f"Analysis complete: {total_findings} findings, {ai_findings_count} AI findings")
        progress.log(f"AI Status set to: {results.get('ai_status', 'Not set')}")
        progress.log(f"Processed {total_packets} packets in {time.time() - progress.start_time:.1f}s")
        progress.log("üéâ Analysis completed successfully!")
        
        # Store results
        st.session_state.analysis_results = results
        
        # Final progress update
        progress.set_phase("Report Generation")
        progress.log("Generating final report...")
        progress.log("Analysis completed successfully!")
        progress.log(f"Total processing time: {time.time() - progress.start_time:.1f}s")
        
        # Clear the progress modal
        progress.clear_display()
        
        # Mark analysis as complete and redirect
        st.session_state.analysis_running = False
        
        # Auto-redirect to results page
        st.session_state.current_page = 'results'
        st.rerun()
        
    except Exception as e:
        progress.clear_display()
        progress.log(f"Critical analysis error: {str(e)}")
        st.error(f"‚ùå Analysis failed: {str(e)}")
        st.session_state.analysis_running = False
    
    finally:
        # Clean up temp file
        if os.path.exists(tmp_file_path):
            os.unlink(tmp_file_path)
            progress.log("Temporary files cleaned up")


def test_progress_tracker():
    """Test the progress tracker display"""
    progress_placeholder = st.empty()
    
    # Create a simple progress class for testing
    class TestProgress:
        def __init__(self, placeholder):
            self.placeholder = placeholder
            self.start_time = time.time()
            self.phase_start_time = time.time()
            self.current_phase = "Test Phase"
            self.last_message = "Testing progress display..."
            self.update_counter = 0
            
        def update_display(self):
            current_time = time.time()
            elapsed = current_time - self.start_time
            self.update_counter += 1
            
            # Always clear and update the placeholder
            self.placeholder.empty()
            with self.placeholder.container():
                st.markdown(f"### üß™ Test Progress Tracker üî¥ LIVE")
                st.markdown(f"**{self.current_phase} ({elapsed:.1f}s)**")
                st.progress(min(100, elapsed * 10) / 100, text=f"Progress: {min(100, elapsed * 10):.1f}% ‚Ä¢ Update #{self.update_counter}")
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("‚è±Ô∏è Elapsed", f"{elapsed:.1f}s")
                with col2:
                    st.metric("üìà Progress", f"{min(100, elapsed * 10):.1f}%")
                with col3:
                    st.metric("üïí Test", "Active")
                
                st.info(f"**Status:** {self.last_message} *({time.strftime('%H:%M:%S')})*")
                
    # Create and display test progress
    test_progress = TestProgress(progress_placeholder)
    
    # Show progress for a few seconds
    for i in range(10):
        test_progress.last_message = f"Test step {i+1}/10 - Progress tracker working!"
        test_progress.update_display()
        time.sleep(0.5)
    
    # Show completion
    test_progress.placeholder.empty()
    with test_progress.placeholder.container():
        st.success("‚úÖ Progress Tracker Test Complete!")
        st.balloons()
    
    time.sleep(2)
    test_progress.placeholder.empty()


def run_demo_analysis(ai_enabled=False, mode="standard"):
    """Run demo analysis"""
    if not IMPORTS_OK:
        st.error("Demo unavailable - Import error detected")
        return
    
    progress_container = st.empty()
    
    with progress_container.container():
        st.markdown("üéÆ Running Demo Analysis...")
        progress_bar = st.progress(0)
    
    try:
        # Get demo results
        demo_results = analyze_sample_pcap()
        
        if ai_enabled:
            # Add AI demo data
            demo_results['ai_findings'] = [
                {
                    'flag_candidate': 'CTF{d3m0_fl4g_h1dd3n_1n_dns}',
                    'confidence': 92,
                    'reasoning': 'Found base64-encoded flag in DNS subdomain query',
                    'source': 'ai_hunting'
                },
                {
                    'flag_candidate': 'FLAG{t1m1ng_4tt4ck_d3t3ct3d}',
                    'confidence': 78,
                    'reasoning': 'Detected timing-based steganography in packet intervals',
                    'source': 'ai_hunting'
                }
            ]
            
            demo_results['ai_suggestions'] = [
                'Decode all base64 strings found in DNS queries',
                'Analyze packet timing patterns for steganographic messages',
                'Check HTTP headers for additional hidden flags'
            ]
        
        progress_bar.progress(100)
        st.text("‚úÖ Demo Complete!")
        
        # Store results
        st.session_state.analysis_results = demo_results
        
        st.success("üéÆ Demo analysis complete!")
        
        # Auto-switch to results
        st.session_state.current_page = 'results'
        st.rerun()
        
    except Exception as e:
        progress_container.empty()
        st.error(f"‚ùå Demo failed: {str(e)}")

def export_results(results, format_type):
    """Export results in specified format"""
    if not IMPORTS_OK:
        st.error("Export unavailable - Import error detected")
        return
    
    try:
        analyzer = WebPcapAnalyzer()
        analyzer.results = results
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"flagsniff_results_{timestamp}.{format_type}"
        
        exported_data = analyzer.export_results(format_type)
        
        # Set appropriate MIME type
        if format_type.lower() == 'csv':
            mime = "text/csv"
        elif format_type.lower() == 'html':
            mime = "text/html"
        else:  # json
            mime = "application/json"
        
        st.download_button(
            label=f"üì• Download {format_type.upper()}",
            data=exported_data,
            file_name=filename,
            mime=mime,
            type="primary"
        )
        
        st.success(f"‚úÖ {format_type.upper()} export ready!")
        
    except Exception as e:
        st.error(f"‚ùå Export failed: {str(e)}")

def main():
    """Main application"""
    
    # Apply theme styles
    st.markdown(get_theme_styles(), unsafe_allow_html=True)
    
    # Handle progress display clearing (fixes NoSessionContext error)
    if st.session_state.get('clear_progress_display', False):
        st.session_state.clear_progress_display = False
        # Progress will be cleared naturally on next rerun
    
    # Render navigation
    render_navigation()
    
    # Render hero section
    render_hero()
    
    # Render current page based on session state
    if st.session_state.current_page == 'analyzer':
        render_analyzer_page()
    elif st.session_state.current_page == 'ai_config':
        render_ai_config_page()
    elif st.session_state.current_page == 'results':
        render_results_page()
    elif st.session_state.current_page == 'about':
        render_about_page()
    else:
        # Fallback to analyzer if unknown page
        st.session_state.current_page = 'analyzer'
        render_analyzer_page()

if __name__ == "__main__":
    main()
